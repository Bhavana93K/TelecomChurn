{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem statement:-\n",
    "\n",
    "In the telecom industry, customers are able to choose from multiple service providers and actively switch from one operator to another. In this highly competitive market, the telecommunications industry experiences an average of 15-25% annual churn rate. Given the fact that it costs 5-10 times more to acquire a new customer than to retain an existing one, customer retention has now become even more important than customer acquisition.\n",
    "\n",
    " - For many incumbent operators, retaining high profitable customers is the number one business goal.\n",
    "\n",
    " - To reduce customer churn, telecom companies need to predict which customers are at high risk of churn.\n",
    "\n",
    " - In this project, we will analyse customer-level data of a leading telecom firm, build predictive models to identify customers at high risk of churn and identify the main indicators of churn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process for Analysis\n",
    "1. Reading, understanding and EDA\n",
    "2. Preparing the data for modelling\n",
    "3. Building the model\n",
    "4. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and understanding the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train.csv file contains both dependent and independent features, while the test.csv contains only the independent variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>circle_id</th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>last_date_of_month_6</th>\n",
       "      <th>last_date_of_month_7</th>\n",
       "      <th>last_date_of_month_8</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>roam_ic_mou_7</th>\n",
       "      <th>roam_ic_mou_8</th>\n",
       "      <th>roam_og_mou_6</th>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <th>roam_og_mou_8</th>\n",
       "      <th>loc_og_t2t_mou_6</th>\n",
       "      <th>loc_og_t2t_mou_7</th>\n",
       "      <th>loc_og_t2t_mou_8</th>\n",
       "      <th>loc_og_t2m_mou_6</th>\n",
       "      <th>loc_og_t2m_mou_7</th>\n",
       "      <th>loc_og_t2m_mou_8</th>\n",
       "      <th>loc_og_t2f_mou_6</th>\n",
       "      <th>loc_og_t2f_mou_7</th>\n",
       "      <th>loc_og_t2f_mou_8</th>\n",
       "      <th>loc_og_t2c_mou_6</th>\n",
       "      <th>loc_og_t2c_mou_7</th>\n",
       "      <th>loc_og_t2c_mou_8</th>\n",
       "      <th>loc_og_mou_6</th>\n",
       "      <th>loc_og_mou_7</th>\n",
       "      <th>loc_og_mou_8</th>\n",
       "      <th>std_og_t2t_mou_6</th>\n",
       "      <th>std_og_t2t_mou_7</th>\n",
       "      <th>std_og_t2t_mou_8</th>\n",
       "      <th>std_og_t2m_mou_6</th>\n",
       "      <th>std_og_t2m_mou_7</th>\n",
       "      <th>std_og_t2m_mou_8</th>\n",
       "      <th>std_og_t2f_mou_6</th>\n",
       "      <th>std_og_t2f_mou_7</th>\n",
       "      <th>std_og_t2f_mou_8</th>\n",
       "      <th>std_og_t2c_mou_6</th>\n",
       "      <th>std_og_t2c_mou_7</th>\n",
       "      <th>std_og_t2c_mou_8</th>\n",
       "      <th>std_og_mou_6</th>\n",
       "      <th>std_og_mou_7</th>\n",
       "      <th>std_og_mou_8</th>\n",
       "      <th>isd_og_mou_6</th>\n",
       "      <th>isd_og_mou_7</th>\n",
       "      <th>isd_og_mou_8</th>\n",
       "      <th>spl_og_mou_6</th>\n",
       "      <th>spl_og_mou_7</th>\n",
       "      <th>spl_og_mou_8</th>\n",
       "      <th>og_others_6</th>\n",
       "      <th>og_others_7</th>\n",
       "      <th>og_others_8</th>\n",
       "      <th>total_og_mou_6</th>\n",
       "      <th>total_og_mou_7</th>\n",
       "      <th>total_og_mou_8</th>\n",
       "      <th>loc_ic_t2t_mou_6</th>\n",
       "      <th>loc_ic_t2t_mou_7</th>\n",
       "      <th>loc_ic_t2t_mou_8</th>\n",
       "      <th>loc_ic_t2m_mou_6</th>\n",
       "      <th>loc_ic_t2m_mou_7</th>\n",
       "      <th>loc_ic_t2m_mou_8</th>\n",
       "      <th>loc_ic_t2f_mou_6</th>\n",
       "      <th>loc_ic_t2f_mou_7</th>\n",
       "      <th>loc_ic_t2f_mou_8</th>\n",
       "      <th>loc_ic_mou_6</th>\n",
       "      <th>loc_ic_mou_7</th>\n",
       "      <th>loc_ic_mou_8</th>\n",
       "      <th>std_ic_t2t_mou_6</th>\n",
       "      <th>std_ic_t2t_mou_7</th>\n",
       "      <th>std_ic_t2t_mou_8</th>\n",
       "      <th>std_ic_t2m_mou_6</th>\n",
       "      <th>std_ic_t2m_mou_7</th>\n",
       "      <th>std_ic_t2m_mou_8</th>\n",
       "      <th>std_ic_t2f_mou_6</th>\n",
       "      <th>std_ic_t2f_mou_7</th>\n",
       "      <th>std_ic_t2f_mou_8</th>\n",
       "      <th>std_ic_t2o_mou_6</th>\n",
       "      <th>std_ic_t2o_mou_7</th>\n",
       "      <th>std_ic_t2o_mou_8</th>\n",
       "      <th>std_ic_mou_6</th>\n",
       "      <th>std_ic_mou_7</th>\n",
       "      <th>std_ic_mou_8</th>\n",
       "      <th>total_ic_mou_6</th>\n",
       "      <th>total_ic_mou_7</th>\n",
       "      <th>total_ic_mou_8</th>\n",
       "      <th>spl_ic_mou_6</th>\n",
       "      <th>spl_ic_mou_7</th>\n",
       "      <th>spl_ic_mou_8</th>\n",
       "      <th>isd_ic_mou_6</th>\n",
       "      <th>isd_ic_mou_7</th>\n",
       "      <th>isd_ic_mou_8</th>\n",
       "      <th>ic_others_6</th>\n",
       "      <th>ic_others_7</th>\n",
       "      <th>ic_others_8</th>\n",
       "      <th>total_rech_num_6</th>\n",
       "      <th>total_rech_num_7</th>\n",
       "      <th>total_rech_num_8</th>\n",
       "      <th>total_rech_amt_6</th>\n",
       "      <th>total_rech_amt_7</th>\n",
       "      <th>total_rech_amt_8</th>\n",
       "      <th>max_rech_amt_6</th>\n",
       "      <th>max_rech_amt_7</th>\n",
       "      <th>max_rech_amt_8</th>\n",
       "      <th>date_of_last_rech_6</th>\n",
       "      <th>date_of_last_rech_7</th>\n",
       "      <th>date_of_last_rech_8</th>\n",
       "      <th>last_day_rch_amt_6</th>\n",
       "      <th>last_day_rch_amt_7</th>\n",
       "      <th>last_day_rch_amt_8</th>\n",
       "      <th>date_of_last_rech_data_6</th>\n",
       "      <th>date_of_last_rech_data_7</th>\n",
       "      <th>date_of_last_rech_data_8</th>\n",
       "      <th>total_rech_data_6</th>\n",
       "      <th>total_rech_data_7</th>\n",
       "      <th>total_rech_data_8</th>\n",
       "      <th>max_rech_data_6</th>\n",
       "      <th>max_rech_data_7</th>\n",
       "      <th>max_rech_data_8</th>\n",
       "      <th>count_rech_2g_6</th>\n",
       "      <th>count_rech_2g_7</th>\n",
       "      <th>count_rech_2g_8</th>\n",
       "      <th>count_rech_3g_6</th>\n",
       "      <th>count_rech_3g_7</th>\n",
       "      <th>count_rech_3g_8</th>\n",
       "      <th>av_rech_amt_data_6</th>\n",
       "      <th>av_rech_amt_data_7</th>\n",
       "      <th>av_rech_amt_data_8</th>\n",
       "      <th>vol_2g_mb_6</th>\n",
       "      <th>vol_2g_mb_7</th>\n",
       "      <th>vol_2g_mb_8</th>\n",
       "      <th>vol_3g_mb_6</th>\n",
       "      <th>vol_3g_mb_7</th>\n",
       "      <th>vol_3g_mb_8</th>\n",
       "      <th>arpu_3g_6</th>\n",
       "      <th>arpu_3g_7</th>\n",
       "      <th>arpu_3g_8</th>\n",
       "      <th>arpu_2g_6</th>\n",
       "      <th>arpu_2g_7</th>\n",
       "      <th>arpu_2g_8</th>\n",
       "      <th>night_pck_user_6</th>\n",
       "      <th>night_pck_user_7</th>\n",
       "      <th>night_pck_user_8</th>\n",
       "      <th>monthly_2g_6</th>\n",
       "      <th>monthly_2g_7</th>\n",
       "      <th>monthly_2g_8</th>\n",
       "      <th>sachet_2g_6</th>\n",
       "      <th>sachet_2g_7</th>\n",
       "      <th>sachet_2g_8</th>\n",
       "      <th>monthly_3g_6</th>\n",
       "      <th>monthly_3g_7</th>\n",
       "      <th>monthly_3g_8</th>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>churn_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>31.277</td>\n",
       "      <td>87.009</td>\n",
       "      <td>7.527</td>\n",
       "      <td>48.58</td>\n",
       "      <td>124.38</td>\n",
       "      <td>1.29</td>\n",
       "      <td>32.24</td>\n",
       "      <td>96.68</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>5.29</td>\n",
       "      <td>16.04</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.53</td>\n",
       "      <td>16.04</td>\n",
       "      <td>2.61</td>\n",
       "      <td>46.34</td>\n",
       "      <td>124.38</td>\n",
       "      <td>1.01</td>\n",
       "      <td>18.75</td>\n",
       "      <td>80.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.09</td>\n",
       "      <td>204.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.21</td>\n",
       "      <td>221.68</td>\n",
       "      <td>3.63</td>\n",
       "      <td>2.43</td>\n",
       "      <td>3.68</td>\n",
       "      <td>7.79</td>\n",
       "      <td>0.83</td>\n",
       "      <td>21.08</td>\n",
       "      <td>16.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.26</td>\n",
       "      <td>24.76</td>\n",
       "      <td>24.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.61</td>\n",
       "      <td>0.21</td>\n",
       "      <td>7.46</td>\n",
       "      <td>19.96</td>\n",
       "      <td>14.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.46</td>\n",
       "      <td>27.58</td>\n",
       "      <td>15.18</td>\n",
       "      <td>11.84</td>\n",
       "      <td>53.04</td>\n",
       "      <td>40.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>6/22/2014</td>\n",
       "      <td>7/10/2014</td>\n",
       "      <td>8/24/2014</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>0.000</td>\n",
       "      <td>122.787</td>\n",
       "      <td>42.953</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.99</td>\n",
       "      <td>30.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22.01</td>\n",
       "      <td>29.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.73</td>\n",
       "      <td>31.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.73</td>\n",
       "      <td>31.66</td>\n",
       "      <td>1.68</td>\n",
       "      <td>19.09</td>\n",
       "      <td>10.53</td>\n",
       "      <td>1.41</td>\n",
       "      <td>18.68</td>\n",
       "      <td>11.09</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.66</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.44</td>\n",
       "      <td>39.44</td>\n",
       "      <td>25.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.44</td>\n",
       "      <td>39.44</td>\n",
       "      <td>25.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>50</td>\n",
       "      <td>6/12/2014</td>\n",
       "      <td>7/10/2014</td>\n",
       "      <td>8/26/2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7/8/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>352.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>60.806</td>\n",
       "      <td>103.176</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.53</td>\n",
       "      <td>15.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>53.99</td>\n",
       "      <td>82.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>12.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.64</td>\n",
       "      <td>12.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.94</td>\n",
       "      <td>82.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.94</td>\n",
       "      <td>84.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.49</td>\n",
       "      <td>99.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.51</td>\n",
       "      <td>6.16</td>\n",
       "      <td>6.49</td>\n",
       "      <td>89.86</td>\n",
       "      <td>25.18</td>\n",
       "      <td>23.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>94.38</td>\n",
       "      <td>31.34</td>\n",
       "      <td>30.01</td>\n",
       "      <td>11.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.21</td>\n",
       "      <td>2.48</td>\n",
       "      <td>6.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>6.38</td>\n",
       "      <td>124.29</td>\n",
       "      <td>33.83</td>\n",
       "      <td>36.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>6/11/2014</td>\n",
       "      <td>7/22/2014</td>\n",
       "      <td>8/24/2014</td>\n",
       "      <td>70</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>156.362</td>\n",
       "      <td>205.260</td>\n",
       "      <td>111.095</td>\n",
       "      <td>7.26</td>\n",
       "      <td>16.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>68.76</td>\n",
       "      <td>78.48</td>\n",
       "      <td>50.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.63</td>\n",
       "      <td>6.99</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37.91</td>\n",
       "      <td>44.89</td>\n",
       "      <td>23.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.03</td>\n",
       "      <td>44.91</td>\n",
       "      <td>48.84</td>\n",
       "      <td>23.63</td>\n",
       "      <td>0.26</td>\n",
       "      <td>12.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.33</td>\n",
       "      <td>25.93</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.16</td>\n",
       "      <td>37.99</td>\n",
       "      <td>4.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.95</td>\n",
       "      <td>9.13</td>\n",
       "      <td>25.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.03</td>\n",
       "      <td>95.98</td>\n",
       "      <td>53.84</td>\n",
       "      <td>24.98</td>\n",
       "      <td>4.84</td>\n",
       "      <td>23.88</td>\n",
       "      <td>53.99</td>\n",
       "      <td>44.23</td>\n",
       "      <td>57.14</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>86.21</td>\n",
       "      <td>49.89</td>\n",
       "      <td>81.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.89</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.89</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.81</td>\n",
       "      <td>95.11</td>\n",
       "      <td>50.18</td>\n",
       "      <td>83.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>160</td>\n",
       "      <td>240</td>\n",
       "      <td>130</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>6/15/2014</td>\n",
       "      <td>7/21/2014</td>\n",
       "      <td>8/25/2014</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>240.708</td>\n",
       "      <td>128.191</td>\n",
       "      <td>101.565</td>\n",
       "      <td>21.28</td>\n",
       "      <td>4.83</td>\n",
       "      <td>6.13</td>\n",
       "      <td>56.99</td>\n",
       "      <td>38.11</td>\n",
       "      <td>9.63</td>\n",
       "      <td>53.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.16</td>\n",
       "      <td>4.83</td>\n",
       "      <td>6.13</td>\n",
       "      <td>36.74</td>\n",
       "      <td>19.88</td>\n",
       "      <td>4.61</td>\n",
       "      <td>11.99</td>\n",
       "      <td>1.23</td>\n",
       "      <td>5.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>58.91</td>\n",
       "      <td>25.94</td>\n",
       "      <td>15.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.26</td>\n",
       "      <td>42.94</td>\n",
       "      <td>15.76</td>\n",
       "      <td>5.44</td>\n",
       "      <td>1.39</td>\n",
       "      <td>2.66</td>\n",
       "      <td>10.58</td>\n",
       "      <td>4.33</td>\n",
       "      <td>19.49</td>\n",
       "      <td>5.51</td>\n",
       "      <td>3.63</td>\n",
       "      <td>6.14</td>\n",
       "      <td>21.54</td>\n",
       "      <td>9.36</td>\n",
       "      <td>28.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.54</td>\n",
       "      <td>9.36</td>\n",
       "      <td>28.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>290</td>\n",
       "      <td>136</td>\n",
       "      <td>122</td>\n",
       "      <td>50</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>6/25/2014</td>\n",
       "      <td>7/26/2014</td>\n",
       "      <td>8/30/2014</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>6/25/2014</td>\n",
       "      <td>7/23/2014</td>\n",
       "      <td>8/20/2014</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>390.8</td>\n",
       "      <td>308.89</td>\n",
       "      <td>213.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  circle_id  loc_og_t2o_mou  std_og_t2o_mou  loc_ic_t2o_mou  \\\n",
       "0   0        109             0.0             0.0             0.0   \n",
       "1   1        109             0.0             0.0             0.0   \n",
       "2   2        109             0.0             0.0             0.0   \n",
       "3   3        109             0.0             0.0             0.0   \n",
       "4   4        109             0.0             0.0             0.0   \n",
       "\n",
       "  last_date_of_month_6 last_date_of_month_7 last_date_of_month_8   arpu_6  \\\n",
       "0            6/30/2014            7/31/2014            8/31/2014   31.277   \n",
       "1            6/30/2014            7/31/2014            8/31/2014    0.000   \n",
       "2            6/30/2014            7/31/2014            8/31/2014   60.806   \n",
       "3            6/30/2014            7/31/2014            8/31/2014  156.362   \n",
       "4            6/30/2014            7/31/2014            8/31/2014  240.708   \n",
       "\n",
       "    arpu_7   arpu_8  onnet_mou_6  onnet_mou_7  onnet_mou_8  offnet_mou_6  \\\n",
       "0   87.009    7.527        48.58       124.38         1.29         32.24   \n",
       "1  122.787   42.953         0.00         0.00         0.00          0.00   \n",
       "2  103.176    0.000         0.53        15.93         0.00         53.99   \n",
       "3  205.260  111.095         7.26        16.01         0.00         68.76   \n",
       "4  128.191  101.565        21.28         4.83         6.13         56.99   \n",
       "\n",
       "   offnet_mou_7  offnet_mou_8  roam_ic_mou_6  roam_ic_mou_7  roam_ic_mou_8  \\\n",
       "0         96.68          2.33           0.00            0.0            0.0   \n",
       "1         25.99         30.89           0.00            0.0            0.0   \n",
       "2         82.05          0.00           0.00            0.0            0.0   \n",
       "3         78.48         50.23           0.00            0.0            0.0   \n",
       "4         38.11          9.63          53.64            0.0            0.0   \n",
       "\n",
       "   roam_og_mou_6  roam_og_mou_7  roam_og_mou_8  loc_og_t2t_mou_6  \\\n",
       "0           0.00            0.0           0.00              2.23   \n",
       "1           0.00            0.0           0.00              0.00   \n",
       "2           0.00            0.0           0.00              0.53   \n",
       "3           0.00            0.0           1.63              6.99   \n",
       "4          15.73            0.0           0.00             10.16   \n",
       "\n",
       "   loc_og_t2t_mou_7  loc_og_t2t_mou_8  loc_og_t2m_mou_6  loc_og_t2m_mou_7  \\\n",
       "0              0.00              0.28              5.29             16.04   \n",
       "1              0.00              0.00              0.00              0.00   \n",
       "2             12.98              0.00             24.11              0.00   \n",
       "3              3.94              0.00             37.91             44.89   \n",
       "4              4.83              6.13             36.74             19.88   \n",
       "\n",
       "   loc_og_t2m_mou_8  loc_og_t2f_mou_6  loc_og_t2f_mou_7  loc_og_t2f_mou_8  \\\n",
       "0              2.33              0.00              0.00              0.00   \n",
       "1              0.00              0.00              0.00              0.00   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3             23.63              0.00              0.00              0.00   \n",
       "4              4.61             11.99              1.23              5.01   \n",
       "\n",
       "   loc_og_t2c_mou_6  loc_og_t2c_mou_7  loc_og_t2c_mou_8  loc_og_mou_6  \\\n",
       "0              0.00              0.00              0.00          7.53   \n",
       "1              0.00             22.01             29.79          0.00   \n",
       "2              2.14              0.00              0.00         24.64   \n",
       "3              0.00              0.00              8.03         44.91   \n",
       "4              0.00              9.85              0.00         58.91   \n",
       "\n",
       "   loc_og_mou_7  loc_og_mou_8  std_og_t2t_mou_6  std_og_t2t_mou_7  \\\n",
       "0         16.04          2.61             46.34            124.38   \n",
       "1          0.00          0.00              0.00              0.00   \n",
       "2         12.98          0.00              0.00              2.94   \n",
       "3         48.84         23.63              0.26             12.06   \n",
       "4         25.94         15.76              0.00              0.00   \n",
       "\n",
       "   std_og_t2t_mou_8  std_og_t2m_mou_6  std_og_t2m_mou_7  std_og_t2m_mou_8  \\\n",
       "0              1.01             18.75             80.61               0.0   \n",
       "1              0.00              0.00              0.00               0.0   \n",
       "2              0.00             28.94             82.05               0.0   \n",
       "3              0.00             15.33             25.93               4.6   \n",
       "4              0.00              4.35              0.00               0.0   \n",
       "\n",
       "   std_og_t2f_mou_6  std_og_t2f_mou_7  std_og_t2f_mou_8  std_og_t2c_mou_6  \\\n",
       "0              0.00               0.0               0.0               0.0   \n",
       "1              0.00               0.0               0.0               0.0   \n",
       "2              0.00               0.0               0.0               0.0   \n",
       "3              0.56               0.0               0.0               0.0   \n",
       "4              0.00               0.0               0.0               0.0   \n",
       "\n",
       "   std_og_t2c_mou_7  std_og_t2c_mou_8  std_og_mou_6  std_og_mou_7  \\\n",
       "0               0.0               0.0         65.09        204.99   \n",
       "1               0.0               0.0          0.00          0.00   \n",
       "2               0.0               0.0         28.94         84.99   \n",
       "3               0.0               0.0         16.16         37.99   \n",
       "4               0.0               0.0          4.35          0.00   \n",
       "\n",
       "   std_og_mou_8  isd_og_mou_6  isd_og_mou_7  isd_og_mou_8  spl_og_mou_6  \\\n",
       "0          1.01           0.0           0.0           0.0          8.20   \n",
       "1          0.00           0.0           0.0           0.0          0.00   \n",
       "2          0.00           0.0           0.0           0.0          2.89   \n",
       "3          4.60           0.0           0.0           0.0         14.95   \n",
       "4          0.00           0.0           0.0           0.0          0.00   \n",
       "\n",
       "   spl_og_mou_7  spl_og_mou_8  og_others_6  og_others_7  og_others_8  \\\n",
       "0          0.63          0.00         0.38          0.0          0.0   \n",
       "1         30.73         31.66         0.00          0.0          0.0   \n",
       "2          1.38          0.00         0.00          0.0          0.0   \n",
       "3          9.13         25.61         0.00          0.0          0.0   \n",
       "4         17.00          0.00         0.00          0.0          0.0   \n",
       "\n",
       "   total_og_mou_6  total_og_mou_7  total_og_mou_8  loc_ic_t2t_mou_6  \\\n",
       "0           81.21          221.68            3.63              2.43   \n",
       "1            0.00           30.73           31.66              1.68   \n",
       "2           56.49           99.36            0.00              4.51   \n",
       "3           76.03           95.98           53.84             24.98   \n",
       "4           63.26           42.94           15.76              5.44   \n",
       "\n",
       "   loc_ic_t2t_mou_7  loc_ic_t2t_mou_8  loc_ic_t2m_mou_6  loc_ic_t2m_mou_7  \\\n",
       "0              3.68              7.79              0.83             21.08   \n",
       "1             19.09             10.53              1.41             18.68   \n",
       "2              6.16              6.49             89.86             25.18   \n",
       "3              4.84             23.88             53.99             44.23   \n",
       "4              1.39              2.66             10.58              4.33   \n",
       "\n",
       "   loc_ic_t2m_mou_8  loc_ic_t2f_mou_6  loc_ic_t2f_mou_7  loc_ic_t2f_mou_8  \\\n",
       "0             16.91              0.00              0.00              0.00   \n",
       "1             11.09              0.35              1.66              3.40   \n",
       "2             23.51              0.00              0.00              0.00   \n",
       "3             57.14              7.23              0.81              0.00   \n",
       "4             19.49              5.51              3.63              6.14   \n",
       "\n",
       "   loc_ic_mou_6  loc_ic_mou_7  loc_ic_mou_8  std_ic_t2t_mou_6  \\\n",
       "0          3.26         24.76         24.71              0.00   \n",
       "1          3.44         39.44         25.03              0.00   \n",
       "2         94.38         31.34         30.01             11.69   \n",
       "3         86.21         49.89         81.03              0.00   \n",
       "4         21.54          9.36         28.31              0.00   \n",
       "\n",
       "   std_ic_t2t_mou_7  std_ic_t2t_mou_8  std_ic_t2m_mou_6  std_ic_t2m_mou_7  \\\n",
       "0              7.61              0.21              7.46             19.96   \n",
       "1              0.00              0.00              0.00              0.00   \n",
       "2              0.00              0.00             18.21              2.48   \n",
       "3              0.00              0.00              8.89              0.28   \n",
       "4              0.00              0.00              0.00              0.00   \n",
       "\n",
       "   std_ic_t2m_mou_8  std_ic_t2f_mou_6  std_ic_t2f_mou_7  std_ic_t2f_mou_8  \\\n",
       "0             14.96               0.0               0.0               0.0   \n",
       "1              0.00               0.0               0.0               0.0   \n",
       "2              6.38               0.0               0.0               0.0   \n",
       "3              2.81               0.0               0.0               0.0   \n",
       "4              0.00               0.0               0.0               0.0   \n",
       "\n",
       "   std_ic_t2o_mou_6  std_ic_t2o_mou_7  std_ic_t2o_mou_8  std_ic_mou_6  \\\n",
       "0               0.0               0.0               0.0          7.46   \n",
       "1               0.0               0.0               0.0          0.00   \n",
       "2               0.0               0.0               0.0         29.91   \n",
       "3               0.0               0.0               0.0          8.89   \n",
       "4               0.0               0.0               0.0          0.00   \n",
       "\n",
       "   std_ic_mou_7  std_ic_mou_8  total_ic_mou_6  total_ic_mou_7  total_ic_mou_8  \\\n",
       "0         27.58         15.18           11.84           53.04           40.56   \n",
       "1          0.00          0.00            3.44           39.44           25.04   \n",
       "2          2.48          6.38          124.29           33.83           36.64   \n",
       "3          0.28          2.81           95.11           50.18           83.84   \n",
       "4          0.00          0.00           21.54            9.36           28.31   \n",
       "\n",
       "   spl_ic_mou_6  spl_ic_mou_7  spl_ic_mou_8  isd_ic_mou_6  isd_ic_mou_7  \\\n",
       "0           0.0           0.0          0.66           0.0           0.0   \n",
       "1           0.0           0.0          0.01           0.0           0.0   \n",
       "2           0.0           0.0          0.00           0.0           0.0   \n",
       "3           0.0           0.0          0.00           0.0           0.0   \n",
       "4           0.0           0.0          0.00           0.0           0.0   \n",
       "\n",
       "   isd_ic_mou_8  ic_others_6  ic_others_7  ic_others_8  total_rech_num_6  \\\n",
       "0           0.0         1.11         0.69         0.00                 3   \n",
       "1           0.0         0.00         0.00         0.00                 3   \n",
       "2           0.0         0.00         0.00         0.25                 2   \n",
       "3           0.0         0.00         0.00         0.00                 2   \n",
       "4           0.0         0.00         0.00         0.00                13   \n",
       "\n",
       "   total_rech_num_7  total_rech_num_8  total_rech_amt_6  total_rech_amt_7  \\\n",
       "0                 2                 2                77                65   \n",
       "1                 4                 5                 0               145   \n",
       "2                 4                 2                70               120   \n",
       "3                 4                 3               160               240   \n",
       "4                10                 8               290               136   \n",
       "\n",
       "   total_rech_amt_8  max_rech_amt_6  max_rech_amt_7  max_rech_amt_8  \\\n",
       "0                10              65              65              10   \n",
       "1                50               0             145              50   \n",
       "2                 0              70              70               0   \n",
       "3               130             110             110              50   \n",
       "4               122              50              41              30   \n",
       "\n",
       "  date_of_last_rech_6 date_of_last_rech_7 date_of_last_rech_8  \\\n",
       "0           6/22/2014           7/10/2014           8/24/2014   \n",
       "1           6/12/2014           7/10/2014           8/26/2014   \n",
       "2           6/11/2014           7/22/2014           8/24/2014   \n",
       "3           6/15/2014           7/21/2014           8/25/2014   \n",
       "4           6/25/2014           7/26/2014           8/30/2014   \n",
       "\n",
       "   last_day_rch_amt_6  last_day_rch_amt_7  last_day_rch_amt_8  \\\n",
       "0                  65                  65                   0   \n",
       "1                   0                   0                   0   \n",
       "2                  70                  50                   0   \n",
       "3                 110                 110                  50   \n",
       "4                  25                  10                  30   \n",
       "\n",
       "  date_of_last_rech_data_6 date_of_last_rech_data_7 date_of_last_rech_data_8  \\\n",
       "0                      NaN                      NaN                      NaN   \n",
       "1                      NaN                 7/8/2014                      NaN   \n",
       "2                      NaN                      NaN                      NaN   \n",
       "3                      NaN                      NaN                      NaN   \n",
       "4                6/25/2014                7/23/2014                8/20/2014   \n",
       "\n",
       "   total_rech_data_6  total_rech_data_7  total_rech_data_8  max_rech_data_6  \\\n",
       "0                NaN                NaN                NaN              NaN   \n",
       "1                NaN                1.0                NaN              NaN   \n",
       "2                NaN                NaN                NaN              NaN   \n",
       "3                NaN                NaN                NaN              NaN   \n",
       "4                7.0                7.0                6.0             25.0   \n",
       "\n",
       "   max_rech_data_7  max_rech_data_8  count_rech_2g_6  count_rech_2g_7  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1            145.0              NaN              NaN              0.0   \n",
       "2              NaN              NaN              NaN              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4             41.0             25.0              7.0              6.0   \n",
       "\n",
       "   count_rech_2g_8  count_rech_3g_6  count_rech_3g_7  count_rech_3g_8  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1              NaN              NaN              1.0              NaN   \n",
       "2              NaN              NaN              NaN              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4              6.0              0.0              1.0              0.0   \n",
       "\n",
       "   av_rech_amt_data_6  av_rech_amt_data_7  av_rech_amt_data_8  vol_2g_mb_6  \\\n",
       "0                 NaN                 NaN                 NaN          0.0   \n",
       "1                 NaN               145.0                 NaN          0.0   \n",
       "2                 NaN                 NaN                 NaN          0.0   \n",
       "3                 NaN                 NaN                 NaN          0.0   \n",
       "4               175.0               191.0               142.0        390.8   \n",
       "\n",
       "   vol_2g_mb_7  vol_2g_mb_8  vol_3g_mb_6  vol_3g_mb_7  vol_3g_mb_8  arpu_3g_6  \\\n",
       "0         0.00         0.00          0.0         0.00          0.0        NaN   \n",
       "1       352.91         0.00          0.0         3.96          0.0        NaN   \n",
       "2         0.00         0.00          0.0         0.00          0.0        NaN   \n",
       "3         0.00         0.00          0.0         0.00          0.0        NaN   \n",
       "4       308.89       213.47          0.0         0.00          0.0        0.0   \n",
       "\n",
       "   arpu_3g_7  arpu_3g_8  arpu_2g_6  arpu_2g_7  arpu_2g_8  night_pck_user_6  \\\n",
       "0        NaN        NaN        NaN        NaN        NaN               NaN   \n",
       "1     122.07        NaN        NaN     122.08        NaN               NaN   \n",
       "2        NaN        NaN        NaN        NaN        NaN               NaN   \n",
       "3        NaN        NaN        NaN        NaN        NaN               NaN   \n",
       "4      35.00        0.0        0.0      35.12        0.0               0.0   \n",
       "\n",
       "   night_pck_user_7  night_pck_user_8  monthly_2g_6  monthly_2g_7  \\\n",
       "0               NaN               NaN             0             0   \n",
       "1               0.0               NaN             0             0   \n",
       "2               NaN               NaN             0             0   \n",
       "3               NaN               NaN             0             0   \n",
       "4               0.0               0.0             0             0   \n",
       "\n",
       "   monthly_2g_8  sachet_2g_6  sachet_2g_7  sachet_2g_8  monthly_3g_6  \\\n",
       "0             0            0            0            0             0   \n",
       "1             0            0            0            0             0   \n",
       "2             0            0            0            0             0   \n",
       "3             0            0            0            0             0   \n",
       "4             0            7            6            6             0   \n",
       "\n",
       "   monthly_3g_7  monthly_3g_8  sachet_3g_6  sachet_3g_7  sachet_3g_8  \\\n",
       "0             0             0            0            0            0   \n",
       "1             1             0            0            0            0   \n",
       "2             0             0            0            0            0   \n",
       "3             0             0            0            0            0   \n",
       "4             0             0            0            1            0   \n",
       "\n",
       "   fb_user_6  fb_user_7  fb_user_8   aon  aug_vbc_3g  jul_vbc_3g  jun_vbc_3g  \\\n",
       "0        NaN        NaN        NaN  1958         0.0         0.0         0.0   \n",
       "1        NaN        1.0        NaN   710         0.0         0.0         0.0   \n",
       "2        NaN        NaN        NaN   882         0.0         0.0         0.0   \n",
       "3        NaN        NaN        NaN   982         0.0         0.0         0.0   \n",
       "4        1.0        1.0        1.0   647         0.0         0.0         0.0   \n",
       "\n",
       "   churn_probability  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the dataset\n",
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69999, 172)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 69999 entries, 0 to 69998\n",
      "Columns: 172 entries, id to churn_probability\n",
      "dtypes: float64(135), int64(28), object(9)\n",
      "memory usage: 91.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>circle_id</th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>roam_ic_mou_7</th>\n",
       "      <th>roam_ic_mou_8</th>\n",
       "      <th>roam_og_mou_6</th>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <th>roam_og_mou_8</th>\n",
       "      <th>loc_og_t2t_mou_6</th>\n",
       "      <th>loc_og_t2t_mou_7</th>\n",
       "      <th>loc_og_t2t_mou_8</th>\n",
       "      <th>loc_og_t2m_mou_6</th>\n",
       "      <th>loc_og_t2m_mou_7</th>\n",
       "      <th>loc_og_t2m_mou_8</th>\n",
       "      <th>loc_og_t2f_mou_6</th>\n",
       "      <th>loc_og_t2f_mou_7</th>\n",
       "      <th>loc_og_t2f_mou_8</th>\n",
       "      <th>loc_og_t2c_mou_6</th>\n",
       "      <th>loc_og_t2c_mou_7</th>\n",
       "      <th>loc_og_t2c_mou_8</th>\n",
       "      <th>loc_og_mou_6</th>\n",
       "      <th>loc_og_mou_7</th>\n",
       "      <th>loc_og_mou_8</th>\n",
       "      <th>std_og_t2t_mou_6</th>\n",
       "      <th>std_og_t2t_mou_7</th>\n",
       "      <th>std_og_t2t_mou_8</th>\n",
       "      <th>std_og_t2m_mou_6</th>\n",
       "      <th>std_og_t2m_mou_7</th>\n",
       "      <th>std_og_t2m_mou_8</th>\n",
       "      <th>std_og_t2f_mou_6</th>\n",
       "      <th>std_og_t2f_mou_7</th>\n",
       "      <th>std_og_t2f_mou_8</th>\n",
       "      <th>std_og_t2c_mou_6</th>\n",
       "      <th>std_og_t2c_mou_7</th>\n",
       "      <th>std_og_t2c_mou_8</th>\n",
       "      <th>std_og_mou_6</th>\n",
       "      <th>std_og_mou_7</th>\n",
       "      <th>std_og_mou_8</th>\n",
       "      <th>isd_og_mou_6</th>\n",
       "      <th>isd_og_mou_7</th>\n",
       "      <th>isd_og_mou_8</th>\n",
       "      <th>spl_og_mou_6</th>\n",
       "      <th>spl_og_mou_7</th>\n",
       "      <th>spl_og_mou_8</th>\n",
       "      <th>og_others_6</th>\n",
       "      <th>og_others_7</th>\n",
       "      <th>og_others_8</th>\n",
       "      <th>total_og_mou_6</th>\n",
       "      <th>total_og_mou_7</th>\n",
       "      <th>total_og_mou_8</th>\n",
       "      <th>loc_ic_t2t_mou_6</th>\n",
       "      <th>loc_ic_t2t_mou_7</th>\n",
       "      <th>loc_ic_t2t_mou_8</th>\n",
       "      <th>loc_ic_t2m_mou_6</th>\n",
       "      <th>loc_ic_t2m_mou_7</th>\n",
       "      <th>loc_ic_t2m_mou_8</th>\n",
       "      <th>loc_ic_t2f_mou_6</th>\n",
       "      <th>loc_ic_t2f_mou_7</th>\n",
       "      <th>loc_ic_t2f_mou_8</th>\n",
       "      <th>loc_ic_mou_6</th>\n",
       "      <th>loc_ic_mou_7</th>\n",
       "      <th>loc_ic_mou_8</th>\n",
       "      <th>std_ic_t2t_mou_6</th>\n",
       "      <th>std_ic_t2t_mou_7</th>\n",
       "      <th>std_ic_t2t_mou_8</th>\n",
       "      <th>std_ic_t2m_mou_6</th>\n",
       "      <th>std_ic_t2m_mou_7</th>\n",
       "      <th>std_ic_t2m_mou_8</th>\n",
       "      <th>std_ic_t2f_mou_6</th>\n",
       "      <th>std_ic_t2f_mou_7</th>\n",
       "      <th>std_ic_t2f_mou_8</th>\n",
       "      <th>std_ic_t2o_mou_6</th>\n",
       "      <th>std_ic_t2o_mou_7</th>\n",
       "      <th>std_ic_t2o_mou_8</th>\n",
       "      <th>std_ic_mou_6</th>\n",
       "      <th>std_ic_mou_7</th>\n",
       "      <th>std_ic_mou_8</th>\n",
       "      <th>total_ic_mou_6</th>\n",
       "      <th>total_ic_mou_7</th>\n",
       "      <th>total_ic_mou_8</th>\n",
       "      <th>spl_ic_mou_6</th>\n",
       "      <th>spl_ic_mou_7</th>\n",
       "      <th>spl_ic_mou_8</th>\n",
       "      <th>isd_ic_mou_6</th>\n",
       "      <th>isd_ic_mou_7</th>\n",
       "      <th>isd_ic_mou_8</th>\n",
       "      <th>ic_others_6</th>\n",
       "      <th>ic_others_7</th>\n",
       "      <th>ic_others_8</th>\n",
       "      <th>total_rech_num_6</th>\n",
       "      <th>total_rech_num_7</th>\n",
       "      <th>total_rech_num_8</th>\n",
       "      <th>total_rech_amt_6</th>\n",
       "      <th>total_rech_amt_7</th>\n",
       "      <th>total_rech_amt_8</th>\n",
       "      <th>max_rech_amt_6</th>\n",
       "      <th>max_rech_amt_7</th>\n",
       "      <th>max_rech_amt_8</th>\n",
       "      <th>last_day_rch_amt_6</th>\n",
       "      <th>last_day_rch_amt_7</th>\n",
       "      <th>last_day_rch_amt_8</th>\n",
       "      <th>total_rech_data_6</th>\n",
       "      <th>total_rech_data_7</th>\n",
       "      <th>total_rech_data_8</th>\n",
       "      <th>max_rech_data_6</th>\n",
       "      <th>max_rech_data_7</th>\n",
       "      <th>max_rech_data_8</th>\n",
       "      <th>count_rech_2g_6</th>\n",
       "      <th>count_rech_2g_7</th>\n",
       "      <th>count_rech_2g_8</th>\n",
       "      <th>count_rech_3g_6</th>\n",
       "      <th>count_rech_3g_7</th>\n",
       "      <th>count_rech_3g_8</th>\n",
       "      <th>av_rech_amt_data_6</th>\n",
       "      <th>av_rech_amt_data_7</th>\n",
       "      <th>av_rech_amt_data_8</th>\n",
       "      <th>vol_2g_mb_6</th>\n",
       "      <th>vol_2g_mb_7</th>\n",
       "      <th>vol_2g_mb_8</th>\n",
       "      <th>vol_3g_mb_6</th>\n",
       "      <th>vol_3g_mb_7</th>\n",
       "      <th>vol_3g_mb_8</th>\n",
       "      <th>arpu_3g_6</th>\n",
       "      <th>arpu_3g_7</th>\n",
       "      <th>arpu_3g_8</th>\n",
       "      <th>arpu_2g_6</th>\n",
       "      <th>arpu_2g_7</th>\n",
       "      <th>arpu_2g_8</th>\n",
       "      <th>night_pck_user_6</th>\n",
       "      <th>night_pck_user_7</th>\n",
       "      <th>night_pck_user_8</th>\n",
       "      <th>monthly_2g_6</th>\n",
       "      <th>monthly_2g_7</th>\n",
       "      <th>monthly_2g_8</th>\n",
       "      <th>sachet_2g_6</th>\n",
       "      <th>sachet_2g_7</th>\n",
       "      <th>sachet_2g_8</th>\n",
       "      <th>monthly_3g_6</th>\n",
       "      <th>monthly_3g_7</th>\n",
       "      <th>monthly_3g_8</th>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>churn_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.0</td>\n",
       "      <td>69297.0</td>\n",
       "      <td>69297.0</td>\n",
       "      <td>69297.0</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.0</td>\n",
       "      <td>67312.0</td>\n",
       "      <td>66296.0</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.0</td>\n",
       "      <td>67312.0</td>\n",
       "      <td>66296.0</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>17568.000000</td>\n",
       "      <td>17865.000000</td>\n",
       "      <td>18417.000000</td>\n",
       "      <td>17568.000000</td>\n",
       "      <td>17865.000000</td>\n",
       "      <td>18417.000000</td>\n",
       "      <td>17568.000000</td>\n",
       "      <td>17865.000000</td>\n",
       "      <td>18417.000000</td>\n",
       "      <td>17568.000000</td>\n",
       "      <td>17865.000000</td>\n",
       "      <td>18417.000000</td>\n",
       "      <td>17568.000000</td>\n",
       "      <td>17865.000000</td>\n",
       "      <td>18417.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>17568.000000</td>\n",
       "      <td>17865.000000</td>\n",
       "      <td>18417.000000</td>\n",
       "      <td>17568.000000</td>\n",
       "      <td>17865.000000</td>\n",
       "      <td>18417.000000</td>\n",
       "      <td>17568.000000</td>\n",
       "      <td>17865.000000</td>\n",
       "      <td>18417.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>17568.000000</td>\n",
       "      <td>17865.000000</td>\n",
       "      <td>18417.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.00000</td>\n",
       "      <td>69999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>34999.000000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>283.134365</td>\n",
       "      <td>278.185912</td>\n",
       "      <td>278.858826</td>\n",
       "      <td>133.153275</td>\n",
       "      <td>133.894438</td>\n",
       "      <td>132.978257</td>\n",
       "      <td>198.874771</td>\n",
       "      <td>197.153383</td>\n",
       "      <td>196.543577</td>\n",
       "      <td>9.765435</td>\n",
       "      <td>7.014568</td>\n",
       "      <td>7.004892</td>\n",
       "      <td>14.186457</td>\n",
       "      <td>9.842191</td>\n",
       "      <td>9.771783</td>\n",
       "      <td>46.904854</td>\n",
       "      <td>46.166503</td>\n",
       "      <td>45.686109</td>\n",
       "      <td>93.238231</td>\n",
       "      <td>90.799240</td>\n",
       "      <td>91.121447</td>\n",
       "      <td>3.743179</td>\n",
       "      <td>3.777031</td>\n",
       "      <td>3.661652</td>\n",
       "      <td>1.126025</td>\n",
       "      <td>1.361052</td>\n",
       "      <td>1.420840</td>\n",
       "      <td>143.893585</td>\n",
       "      <td>140.750120</td>\n",
       "      <td>140.476486</td>\n",
       "      <td>80.619382</td>\n",
       "      <td>83.775851</td>\n",
       "      <td>83.471486</td>\n",
       "      <td>88.152110</td>\n",
       "      <td>91.538615</td>\n",
       "      <td>90.586999</td>\n",
       "      <td>1.126377</td>\n",
       "      <td>1.084062</td>\n",
       "      <td>1.057739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.900601</td>\n",
       "      <td>176.401217</td>\n",
       "      <td>175.118852</td>\n",
       "      <td>0.845763</td>\n",
       "      <td>0.811100</td>\n",
       "      <td>0.841648</td>\n",
       "      <td>3.958619</td>\n",
       "      <td>4.976783</td>\n",
       "      <td>5.045027</td>\n",
       "      <td>0.462581</td>\n",
       "      <td>0.024425</td>\n",
       "      <td>0.033059</td>\n",
       "      <td>306.451436</td>\n",
       "      <td>310.572674</td>\n",
       "      <td>304.513065</td>\n",
       "      <td>48.043255</td>\n",
       "      <td>47.882736</td>\n",
       "      <td>47.256388</td>\n",
       "      <td>107.152439</td>\n",
       "      <td>106.489856</td>\n",
       "      <td>108.154731</td>\n",
       "      <td>12.050672</td>\n",
       "      <td>12.563665</td>\n",
       "      <td>11.716763</td>\n",
       "      <td>167.255126</td>\n",
       "      <td>166.945103</td>\n",
       "      <td>167.136761</td>\n",
       "      <td>9.476958</td>\n",
       "      <td>9.873468</td>\n",
       "      <td>9.910217</td>\n",
       "      <td>20.734858</td>\n",
       "      <td>21.685359</td>\n",
       "      <td>21.089042</td>\n",
       "      <td>2.146273</td>\n",
       "      <td>2.199395</td>\n",
       "      <td>2.075179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.360632</td>\n",
       "      <td>33.760809</td>\n",
       "      <td>33.077030</td>\n",
       "      <td>199.710640</td>\n",
       "      <td>201.878029</td>\n",
       "      <td>198.486034</td>\n",
       "      <td>0.061932</td>\n",
       "      <td>0.033371</td>\n",
       "      <td>0.040392</td>\n",
       "      <td>7.394167</td>\n",
       "      <td>8.171162</td>\n",
       "      <td>8.348424</td>\n",
       "      <td>0.854063</td>\n",
       "      <td>1.019680</td>\n",
       "      <td>0.963214</td>\n",
       "      <td>7.566522</td>\n",
       "      <td>7.706667</td>\n",
       "      <td>7.224932</td>\n",
       "      <td>328.139788</td>\n",
       "      <td>322.376363</td>\n",
       "      <td>323.846355</td>\n",
       "      <td>104.569265</td>\n",
       "      <td>104.137573</td>\n",
       "      <td>107.540351</td>\n",
       "      <td>63.426949</td>\n",
       "      <td>59.294218</td>\n",
       "      <td>62.489478</td>\n",
       "      <td>2.467612</td>\n",
       "      <td>2.679989</td>\n",
       "      <td>2.652441</td>\n",
       "      <td>126.500000</td>\n",
       "      <td>126.402071</td>\n",
       "      <td>125.374925</td>\n",
       "      <td>1.865323</td>\n",
       "      <td>2.056311</td>\n",
       "      <td>2.016018</td>\n",
       "      <td>0.602288</td>\n",
       "      <td>0.623678</td>\n",
       "      <td>0.636423</td>\n",
       "      <td>192.831096</td>\n",
       "      <td>201.455940</td>\n",
       "      <td>196.815792</td>\n",
       "      <td>51.773924</td>\n",
       "      <td>51.240204</td>\n",
       "      <td>50.127506</td>\n",
       "      <td>122.171882</td>\n",
       "      <td>128.934444</td>\n",
       "      <td>135.486541</td>\n",
       "      <td>90.069931</td>\n",
       "      <td>89.115767</td>\n",
       "      <td>90.618564</td>\n",
       "      <td>86.863900</td>\n",
       "      <td>85.846074</td>\n",
       "      <td>86.348404</td>\n",
       "      <td>0.025273</td>\n",
       "      <td>0.024069</td>\n",
       "      <td>0.021013</td>\n",
       "      <td>0.079287</td>\n",
       "      <td>0.083401</td>\n",
       "      <td>0.080930</td>\n",
       "      <td>0.388863</td>\n",
       "      <td>0.441406</td>\n",
       "      <td>0.449492</td>\n",
       "      <td>0.075815</td>\n",
       "      <td>0.077730</td>\n",
       "      <td>0.081958</td>\n",
       "      <td>0.075344</td>\n",
       "      <td>0.081444</td>\n",
       "      <td>0.085487</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.909544</td>\n",
       "      <td>0.890319</td>\n",
       "      <td>1220.639709</td>\n",
       "      <td>68.108597</td>\n",
       "      <td>65.935830</td>\n",
       "      <td>60.07674</td>\n",
       "      <td>0.101887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20207.115084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>334.213918</td>\n",
       "      <td>344.366927</td>\n",
       "      <td>351.924315</td>\n",
       "      <td>299.963093</td>\n",
       "      <td>311.277193</td>\n",
       "      <td>311.896596</td>\n",
       "      <td>316.818355</td>\n",
       "      <td>322.482226</td>\n",
       "      <td>324.089234</td>\n",
       "      <td>57.374429</td>\n",
       "      <td>55.960985</td>\n",
       "      <td>53.408135</td>\n",
       "      <td>73.469261</td>\n",
       "      <td>58.511894</td>\n",
       "      <td>64.618388</td>\n",
       "      <td>150.971758</td>\n",
       "      <td>154.739002</td>\n",
       "      <td>153.716880</td>\n",
       "      <td>162.046699</td>\n",
       "      <td>153.852597</td>\n",
       "      <td>152.997805</td>\n",
       "      <td>13.319542</td>\n",
       "      <td>13.568110</td>\n",
       "      <td>13.009193</td>\n",
       "      <td>5.741811</td>\n",
       "      <td>7.914113</td>\n",
       "      <td>6.542202</td>\n",
       "      <td>252.034597</td>\n",
       "      <td>246.313148</td>\n",
       "      <td>245.342359</td>\n",
       "      <td>255.098355</td>\n",
       "      <td>266.693254</td>\n",
       "      <td>267.021929</td>\n",
       "      <td>255.771554</td>\n",
       "      <td>267.532089</td>\n",
       "      <td>270.032002</td>\n",
       "      <td>8.136645</td>\n",
       "      <td>8.325206</td>\n",
       "      <td>7.696853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392.046600</td>\n",
       "      <td>409.299501</td>\n",
       "      <td>410.697098</td>\n",
       "      <td>29.747486</td>\n",
       "      <td>29.220073</td>\n",
       "      <td>29.563367</td>\n",
       "      <td>15.854529</td>\n",
       "      <td>22.229842</td>\n",
       "      <td>17.708507</td>\n",
       "      <td>4.768437</td>\n",
       "      <td>1.716430</td>\n",
       "      <td>2.232547</td>\n",
       "      <td>465.502866</td>\n",
       "      <td>479.131770</td>\n",
       "      <td>477.936832</td>\n",
       "      <td>140.499757</td>\n",
       "      <td>147.761124</td>\n",
       "      <td>141.249368</td>\n",
       "      <td>168.455999</td>\n",
       "      <td>165.452459</td>\n",
       "      <td>166.223461</td>\n",
       "      <td>39.416076</td>\n",
       "      <td>43.495179</td>\n",
       "      <td>38.606895</td>\n",
       "      <td>252.576231</td>\n",
       "      <td>254.688718</td>\n",
       "      <td>249.288410</td>\n",
       "      <td>51.664472</td>\n",
       "      <td>56.137824</td>\n",
       "      <td>54.248186</td>\n",
       "      <td>80.294236</td>\n",
       "      <td>87.314510</td>\n",
       "      <td>81.534344</td>\n",
       "      <td>16.522232</td>\n",
       "      <td>16.171533</td>\n",
       "      <td>15.865403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.381082</td>\n",
       "      <td>114.142230</td>\n",
       "      <td>108.469864</td>\n",
       "      <td>290.114823</td>\n",
       "      <td>296.771338</td>\n",
       "      <td>288.336731</td>\n",
       "      <td>0.164823</td>\n",
       "      <td>0.137322</td>\n",
       "      <td>0.148417</td>\n",
       "      <td>60.951165</td>\n",
       "      <td>63.604165</td>\n",
       "      <td>63.097570</td>\n",
       "      <td>12.149144</td>\n",
       "      <td>13.225373</td>\n",
       "      <td>11.697686</td>\n",
       "      <td>7.041452</td>\n",
       "      <td>7.050614</td>\n",
       "      <td>7.195597</td>\n",
       "      <td>404.211068</td>\n",
       "      <td>411.070120</td>\n",
       "      <td>426.181405</td>\n",
       "      <td>121.407701</td>\n",
       "      <td>120.782543</td>\n",
       "      <td>124.396750</td>\n",
       "      <td>97.954876</td>\n",
       "      <td>95.429492</td>\n",
       "      <td>101.996729</td>\n",
       "      <td>2.794610</td>\n",
       "      <td>3.073472</td>\n",
       "      <td>3.101265</td>\n",
       "      <td>109.352573</td>\n",
       "      <td>109.459266</td>\n",
       "      <td>109.648799</td>\n",
       "      <td>2.566377</td>\n",
       "      <td>2.799916</td>\n",
       "      <td>2.728246</td>\n",
       "      <td>1.279297</td>\n",
       "      <td>1.401230</td>\n",
       "      <td>1.457058</td>\n",
       "      <td>190.623115</td>\n",
       "      <td>198.346141</td>\n",
       "      <td>192.280532</td>\n",
       "      <td>212.513909</td>\n",
       "      <td>211.114667</td>\n",
       "      <td>213.101403</td>\n",
       "      <td>554.869965</td>\n",
       "      <td>554.096072</td>\n",
       "      <td>568.310234</td>\n",
       "      <td>193.600413</td>\n",
       "      <td>195.826990</td>\n",
       "      <td>189.907986</td>\n",
       "      <td>171.321203</td>\n",
       "      <td>178.067280</td>\n",
       "      <td>170.297094</td>\n",
       "      <td>0.156958</td>\n",
       "      <td>0.153269</td>\n",
       "      <td>0.143432</td>\n",
       "      <td>0.294719</td>\n",
       "      <td>0.304802</td>\n",
       "      <td>0.299254</td>\n",
       "      <td>1.494206</td>\n",
       "      <td>1.651012</td>\n",
       "      <td>1.632450</td>\n",
       "      <td>0.358905</td>\n",
       "      <td>0.383189</td>\n",
       "      <td>0.381821</td>\n",
       "      <td>0.573003</td>\n",
       "      <td>0.634547</td>\n",
       "      <td>0.680035</td>\n",
       "      <td>0.276907</td>\n",
       "      <td>0.286842</td>\n",
       "      <td>0.312501</td>\n",
       "      <td>952.426321</td>\n",
       "      <td>269.328659</td>\n",
       "      <td>267.899034</td>\n",
       "      <td>257.22681</td>\n",
       "      <td>0.302502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2258.709000</td>\n",
       "      <td>-1289.715000</td>\n",
       "      <td>-945.808000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-20.380000</td>\n",
       "      <td>-26.040000</td>\n",
       "      <td>-24.490000</td>\n",
       "      <td>-35.830000</td>\n",
       "      <td>-13.090000</td>\n",
       "      <td>-55.830000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17499.500000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.581000</td>\n",
       "      <td>86.714000</td>\n",
       "      <td>84.095000</td>\n",
       "      <td>7.410000</td>\n",
       "      <td>6.675000</td>\n",
       "      <td>6.410000</td>\n",
       "      <td>34.860000</td>\n",
       "      <td>32.240000</td>\n",
       "      <td>31.575000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>1.610000</td>\n",
       "      <td>9.920000</td>\n",
       "      <td>10.090000</td>\n",
       "      <td>9.830000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.235000</td>\n",
       "      <td>17.590000</td>\n",
       "      <td>17.237500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.780000</td>\n",
       "      <td>42.910000</td>\n",
       "      <td>38.710000</td>\n",
       "      <td>3.030000</td>\n",
       "      <td>3.260000</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>17.390000</td>\n",
       "      <td>18.610000</td>\n",
       "      <td>18.940000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.630000</td>\n",
       "      <td>32.710000</td>\n",
       "      <td>32.810000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>38.640000</td>\n",
       "      <td>41.340000</td>\n",
       "      <td>38.290000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>468.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>34999.000000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.484000</td>\n",
       "      <td>191.588000</td>\n",
       "      <td>192.234000</td>\n",
       "      <td>34.110000</td>\n",
       "      <td>32.280000</td>\n",
       "      <td>32.100000</td>\n",
       "      <td>96.480000</td>\n",
       "      <td>91.885000</td>\n",
       "      <td>91.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.910000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>11.740000</td>\n",
       "      <td>41.030000</td>\n",
       "      <td>40.170000</td>\n",
       "      <td>40.350000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.190000</td>\n",
       "      <td>63.430000</td>\n",
       "      <td>63.520000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.980000</td>\n",
       "      <td>3.710000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.730000</td>\n",
       "      <td>11.260000</td>\n",
       "      <td>10.505000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>145.280000</td>\n",
       "      <td>141.230000</td>\n",
       "      <td>138.360000</td>\n",
       "      <td>15.740000</td>\n",
       "      <td>15.830000</td>\n",
       "      <td>16.040000</td>\n",
       "      <td>56.460000</td>\n",
       "      <td>56.930000</td>\n",
       "      <td>58.210000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>92.430000</td>\n",
       "      <td>92.510000</td>\n",
       "      <td>93.890000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.040000</td>\n",
       "      <td>2.060000</td>\n",
       "      <td>2.030000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.910000</td>\n",
       "      <td>5.980000</td>\n",
       "      <td>5.830000</td>\n",
       "      <td>114.780000</td>\n",
       "      <td>116.330000</td>\n",
       "      <td>114.610000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>11.300000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>9.090000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>868.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>52498.500000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>370.791000</td>\n",
       "      <td>365.369500</td>\n",
       "      <td>369.909000</td>\n",
       "      <td>119.390000</td>\n",
       "      <td>115.837500</td>\n",
       "      <td>115.060000</td>\n",
       "      <td>232.990000</td>\n",
       "      <td>227.630000</td>\n",
       "      <td>229.345000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.740000</td>\n",
       "      <td>39.760000</td>\n",
       "      <td>39.895000</td>\n",
       "      <td>110.430000</td>\n",
       "      <td>107.540000</td>\n",
       "      <td>109.245000</td>\n",
       "      <td>2.060000</td>\n",
       "      <td>2.080000</td>\n",
       "      <td>2.030000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>167.880000</td>\n",
       "      <td>163.932500</td>\n",
       "      <td>165.615000</td>\n",
       "      <td>31.020000</td>\n",
       "      <td>31.300000</td>\n",
       "      <td>30.760000</td>\n",
       "      <td>53.745000</td>\n",
       "      <td>54.640000</td>\n",
       "      <td>52.660000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146.335000</td>\n",
       "      <td>151.645000</td>\n",
       "      <td>149.015000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>3.660000</td>\n",
       "      <td>4.002500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>374.305000</td>\n",
       "      <td>380.045000</td>\n",
       "      <td>370.895000</td>\n",
       "      <td>46.980000</td>\n",
       "      <td>45.690000</td>\n",
       "      <td>46.280000</td>\n",
       "      <td>132.020000</td>\n",
       "      <td>131.010000</td>\n",
       "      <td>134.380000</td>\n",
       "      <td>8.140000</td>\n",
       "      <td>8.230000</td>\n",
       "      <td>8.090000</td>\n",
       "      <td>208.325000</td>\n",
       "      <td>205.530000</td>\n",
       "      <td>208.060000</td>\n",
       "      <td>4.060000</td>\n",
       "      <td>4.180000</td>\n",
       "      <td>4.052500</td>\n",
       "      <td>14.960000</td>\n",
       "      <td>15.830000</td>\n",
       "      <td>15.310000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.780000</td>\n",
       "      <td>28.160000</td>\n",
       "      <td>27.615000</td>\n",
       "      <td>251.070000</td>\n",
       "      <td>249.470000</td>\n",
       "      <td>249.710000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>438.000000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>122.070000</td>\n",
       "      <td>120.860000</td>\n",
       "      <td>122.070000</td>\n",
       "      <td>122.070000</td>\n",
       "      <td>122.070000</td>\n",
       "      <td>122.070000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1813.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>69998.000000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27731.088000</td>\n",
       "      <td>35145.834000</td>\n",
       "      <td>33543.624000</td>\n",
       "      <td>7376.710000</td>\n",
       "      <td>8157.780000</td>\n",
       "      <td>10752.560000</td>\n",
       "      <td>8362.360000</td>\n",
       "      <td>7043.980000</td>\n",
       "      <td>14007.340000</td>\n",
       "      <td>2850.980000</td>\n",
       "      <td>4155.830000</td>\n",
       "      <td>4169.810000</td>\n",
       "      <td>3775.110000</td>\n",
       "      <td>2812.040000</td>\n",
       "      <td>5337.040000</td>\n",
       "      <td>6431.330000</td>\n",
       "      <td>7400.660000</td>\n",
       "      <td>10752.560000</td>\n",
       "      <td>4696.830000</td>\n",
       "      <td>4557.140000</td>\n",
       "      <td>4961.330000</td>\n",
       "      <td>617.580000</td>\n",
       "      <td>815.330000</td>\n",
       "      <td>588.290000</td>\n",
       "      <td>342.860000</td>\n",
       "      <td>916.240000</td>\n",
       "      <td>351.830000</td>\n",
       "      <td>10643.380000</td>\n",
       "      <td>7674.780000</td>\n",
       "      <td>11039.910000</td>\n",
       "      <td>7366.580000</td>\n",
       "      <td>8133.660000</td>\n",
       "      <td>8014.430000</td>\n",
       "      <td>8314.760000</td>\n",
       "      <td>6622.540000</td>\n",
       "      <td>13950.040000</td>\n",
       "      <td>628.560000</td>\n",
       "      <td>465.790000</td>\n",
       "      <td>354.160000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8432.990000</td>\n",
       "      <td>8155.530000</td>\n",
       "      <td>13980.060000</td>\n",
       "      <td>5900.660000</td>\n",
       "      <td>5490.280000</td>\n",
       "      <td>5681.540000</td>\n",
       "      <td>1023.210000</td>\n",
       "      <td>2372.510000</td>\n",
       "      <td>1075.080000</td>\n",
       "      <td>800.890000</td>\n",
       "      <td>270.240000</td>\n",
       "      <td>394.930000</td>\n",
       "      <td>10674.030000</td>\n",
       "      <td>8285.640000</td>\n",
       "      <td>14043.060000</td>\n",
       "      <td>5315.590000</td>\n",
       "      <td>9324.660000</td>\n",
       "      <td>10696.230000</td>\n",
       "      <td>4450.740000</td>\n",
       "      <td>4455.830000</td>\n",
       "      <td>6274.190000</td>\n",
       "      <td>1872.340000</td>\n",
       "      <td>1983.010000</td>\n",
       "      <td>1676.580000</td>\n",
       "      <td>7454.630000</td>\n",
       "      <td>9669.910000</td>\n",
       "      <td>10830.160000</td>\n",
       "      <td>3336.380000</td>\n",
       "      <td>4708.710000</td>\n",
       "      <td>3930.240000</td>\n",
       "      <td>5647.160000</td>\n",
       "      <td>6141.880000</td>\n",
       "      <td>5512.760000</td>\n",
       "      <td>1351.110000</td>\n",
       "      <td>1136.080000</td>\n",
       "      <td>1394.890000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5712.110000</td>\n",
       "      <td>6745.760000</td>\n",
       "      <td>5658.740000</td>\n",
       "      <td>7716.140000</td>\n",
       "      <td>9699.010000</td>\n",
       "      <td>10830.380000</td>\n",
       "      <td>19.760000</td>\n",
       "      <td>13.460000</td>\n",
       "      <td>16.860000</td>\n",
       "      <td>6789.410000</td>\n",
       "      <td>5289.540000</td>\n",
       "      <td>4127.010000</td>\n",
       "      <td>1362.940000</td>\n",
       "      <td>1495.940000</td>\n",
       "      <td>1209.860000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>35190.000000</td>\n",
       "      <td>40335.000000</td>\n",
       "      <td>45320.000000</td>\n",
       "      <td>4010.000000</td>\n",
       "      <td>3299.000000</td>\n",
       "      <td>4449.000000</td>\n",
       "      <td>4010.000000</td>\n",
       "      <td>3100.000000</td>\n",
       "      <td>4449.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1555.000000</td>\n",
       "      <td>1555.000000</td>\n",
       "      <td>1555.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>5920.000000</td>\n",
       "      <td>4365.000000</td>\n",
       "      <td>4076.000000</td>\n",
       "      <td>10285.900000</td>\n",
       "      <td>7873.550000</td>\n",
       "      <td>11117.610000</td>\n",
       "      <td>45735.400000</td>\n",
       "      <td>28144.120000</td>\n",
       "      <td>30036.060000</td>\n",
       "      <td>5054.370000</td>\n",
       "      <td>4980.900000</td>\n",
       "      <td>3716.900000</td>\n",
       "      <td>5054.350000</td>\n",
       "      <td>4809.360000</td>\n",
       "      <td>3483.170000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4337.000000</td>\n",
       "      <td>12916.220000</td>\n",
       "      <td>9165.600000</td>\n",
       "      <td>11166.21000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  circle_id  loc_og_t2o_mou  std_og_t2o_mou  \\\n",
       "count  69999.000000    69999.0         69297.0         69297.0   \n",
       "mean   34999.000000      109.0             0.0             0.0   \n",
       "std    20207.115084        0.0             0.0             0.0   \n",
       "min        0.000000      109.0             0.0             0.0   \n",
       "25%    17499.500000      109.0             0.0             0.0   \n",
       "50%    34999.000000      109.0             0.0             0.0   \n",
       "75%    52498.500000      109.0             0.0             0.0   \n",
       "max    69998.000000      109.0             0.0             0.0   \n",
       "\n",
       "       loc_ic_t2o_mou        arpu_6        arpu_7        arpu_8   onnet_mou_6  \\\n",
       "count         69297.0  69999.000000  69999.000000  69999.000000  67231.000000   \n",
       "mean              0.0    283.134365    278.185912    278.858826    133.153275   \n",
       "std               0.0    334.213918    344.366927    351.924315    299.963093   \n",
       "min               0.0  -2258.709000  -1289.715000   -945.808000      0.000000   \n",
       "25%               0.0     93.581000     86.714000     84.095000      7.410000   \n",
       "50%               0.0    197.484000    191.588000    192.234000     34.110000   \n",
       "75%               0.0    370.791000    365.369500    369.909000    119.390000   \n",
       "max               0.0  27731.088000  35145.834000  33543.624000   7376.710000   \n",
       "\n",
       "        onnet_mou_7   onnet_mou_8  offnet_mou_6  offnet_mou_7  offnet_mou_8  \\\n",
       "count  67312.000000  66296.000000  67231.000000  67312.000000  66296.000000   \n",
       "mean     133.894438    132.978257    198.874771    197.153383    196.543577   \n",
       "std      311.277193    311.896596    316.818355    322.482226    324.089234   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        6.675000      6.410000     34.860000     32.240000     31.575000   \n",
       "50%       32.280000     32.100000     96.480000     91.885000     91.800000   \n",
       "75%      115.837500    115.060000    232.990000    227.630000    229.345000   \n",
       "max     8157.780000  10752.560000   8362.360000   7043.980000  14007.340000   \n",
       "\n",
       "       roam_ic_mou_6  roam_ic_mou_7  roam_ic_mou_8  roam_og_mou_6  \\\n",
       "count   67231.000000   67312.000000   66296.000000   67231.000000   \n",
       "mean        9.765435       7.014568       7.004892      14.186457   \n",
       "std        57.374429      55.960985      53.408135      73.469261   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max      2850.980000    4155.830000    4169.810000    3775.110000   \n",
       "\n",
       "       roam_og_mou_7  roam_og_mou_8  loc_og_t2t_mou_6  loc_og_t2t_mou_7  \\\n",
       "count   67312.000000   66296.000000      67231.000000      67312.000000   \n",
       "mean        9.842191       9.771783         46.904854         46.166503   \n",
       "std        58.511894      64.618388        150.971758        154.739002   \n",
       "min         0.000000       0.000000          0.000000          0.000000   \n",
       "25%         0.000000       0.000000          1.660000          1.650000   \n",
       "50%         0.000000       0.000000         11.910000         11.580000   \n",
       "75%         0.000000       0.000000         40.740000         39.760000   \n",
       "max      2812.040000    5337.040000       6431.330000       7400.660000   \n",
       "\n",
       "       loc_og_t2t_mou_8  loc_og_t2m_mou_6  loc_og_t2m_mou_7  loc_og_t2m_mou_8  \\\n",
       "count      66296.000000      67231.000000      67312.000000      66296.000000   \n",
       "mean          45.686109         93.238231         90.799240         91.121447   \n",
       "std          153.716880        162.046699        153.852597        152.997805   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            1.610000          9.920000         10.090000          9.830000   \n",
       "50%           11.740000         41.030000         40.170000         40.350000   \n",
       "75%           39.895000        110.430000        107.540000        109.245000   \n",
       "max        10752.560000       4696.830000       4557.140000       4961.330000   \n",
       "\n",
       "       loc_og_t2f_mou_6  loc_og_t2f_mou_7  loc_og_t2f_mou_8  loc_og_t2c_mou_6  \\\n",
       "count      67231.000000      67312.000000      66296.000000      67231.000000   \n",
       "mean           3.743179          3.777031          3.661652          1.126025   \n",
       "std           13.319542         13.568110         13.009193          5.741811   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            0.000000          0.000000          0.000000          0.000000   \n",
       "50%            0.000000          0.000000          0.000000          0.000000   \n",
       "75%            2.060000          2.080000          2.030000          0.000000   \n",
       "max          617.580000        815.330000        588.290000        342.860000   \n",
       "\n",
       "       loc_og_t2c_mou_7  loc_og_t2c_mou_8  loc_og_mou_6  loc_og_mou_7  \\\n",
       "count      67312.000000      66296.000000  67231.000000  67312.000000   \n",
       "mean           1.361052          1.420840    143.893585    140.750120   \n",
       "std            7.914113          6.542202    252.034597    246.313148   \n",
       "min            0.000000          0.000000      0.000000      0.000000   \n",
       "25%            0.000000          0.000000     17.235000     17.590000   \n",
       "50%            0.000000          0.000000     65.190000     63.430000   \n",
       "75%            0.000000          0.000000    167.880000    163.932500   \n",
       "max          916.240000        351.830000  10643.380000   7674.780000   \n",
       "\n",
       "       loc_og_mou_8  std_og_t2t_mou_6  std_og_t2t_mou_7  std_og_t2t_mou_8  \\\n",
       "count  66296.000000      67231.000000      67312.000000      66296.000000   \n",
       "mean     140.476486         80.619382         83.775851         83.471486   \n",
       "std      245.342359        255.098355        266.693254        267.021929   \n",
       "min        0.000000          0.000000          0.000000          0.000000   \n",
       "25%       17.237500          0.000000          0.000000          0.000000   \n",
       "50%       63.520000          0.000000          0.000000          0.000000   \n",
       "75%      165.615000         31.020000         31.300000         30.760000   \n",
       "max    11039.910000       7366.580000       8133.660000       8014.430000   \n",
       "\n",
       "       std_og_t2m_mou_6  std_og_t2m_mou_7  std_og_t2m_mou_8  std_og_t2f_mou_6  \\\n",
       "count      67231.000000      67312.000000      66296.000000      67231.000000   \n",
       "mean          88.152110         91.538615         90.586999          1.126377   \n",
       "std          255.771554        267.532089        270.032002          8.136645   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            0.000000          0.000000          0.000000          0.000000   \n",
       "50%            3.980000          3.710000          3.300000          0.000000   \n",
       "75%           53.745000         54.640000         52.660000          0.000000   \n",
       "max         8314.760000       6622.540000      13950.040000        628.560000   \n",
       "\n",
       "       std_og_t2f_mou_7  std_og_t2f_mou_8  std_og_t2c_mou_6  std_og_t2c_mou_7  \\\n",
       "count      67312.000000      66296.000000           67231.0           67312.0   \n",
       "mean           1.084062          1.057739               0.0               0.0   \n",
       "std            8.325206          7.696853               0.0               0.0   \n",
       "min            0.000000          0.000000               0.0               0.0   \n",
       "25%            0.000000          0.000000               0.0               0.0   \n",
       "50%            0.000000          0.000000               0.0               0.0   \n",
       "75%            0.000000          0.000000               0.0               0.0   \n",
       "max          465.790000        354.160000               0.0               0.0   \n",
       "\n",
       "       std_og_t2c_mou_8  std_og_mou_6  std_og_mou_7  std_og_mou_8  \\\n",
       "count           66296.0  67231.000000  67312.000000  66296.000000   \n",
       "mean                0.0    169.900601    176.401217    175.118852   \n",
       "std                 0.0    392.046600    409.299501    410.697098   \n",
       "min                 0.0      0.000000      0.000000      0.000000   \n",
       "25%                 0.0      0.000000      0.000000      0.000000   \n",
       "50%                 0.0     11.730000     11.260000     10.505000   \n",
       "75%                 0.0    146.335000    151.645000    149.015000   \n",
       "max                 0.0   8432.990000   8155.530000  13980.060000   \n",
       "\n",
       "       isd_og_mou_6  isd_og_mou_7  isd_og_mou_8  spl_og_mou_6  spl_og_mou_7  \\\n",
       "count  67231.000000  67312.000000  66296.000000  67231.000000  67312.000000   \n",
       "mean       0.845763      0.811100      0.841648      3.958619      4.976783   \n",
       "std       29.747486     29.220073     29.563367     15.854529     22.229842   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      2.400000      3.660000   \n",
       "max     5900.660000   5490.280000   5681.540000   1023.210000   2372.510000   \n",
       "\n",
       "       spl_og_mou_8   og_others_6   og_others_7   og_others_8  total_og_mou_6  \\\n",
       "count  66296.000000  67231.000000  67312.000000  66296.000000    69999.000000   \n",
       "mean       5.045027      0.462581      0.024425      0.033059      306.451436   \n",
       "std       17.708507      4.768437      1.716430      2.232547      465.502866   \n",
       "min        0.000000      0.000000      0.000000      0.000000        0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000       44.780000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      145.280000   \n",
       "75%        4.002500      0.000000      0.000000      0.000000      374.305000   \n",
       "max     1075.080000    800.890000    270.240000    394.930000    10674.030000   \n",
       "\n",
       "       total_og_mou_7  total_og_mou_8  loc_ic_t2t_mou_6  loc_ic_t2t_mou_7  \\\n",
       "count    69999.000000    69999.000000      67231.000000      67312.000000   \n",
       "mean       310.572674      304.513065         48.043255         47.882736   \n",
       "std        479.131770      477.936832        140.499757        147.761124   \n",
       "min          0.000000        0.000000          0.000000          0.000000   \n",
       "25%         42.910000       38.710000          3.030000          3.260000   \n",
       "50%        141.230000      138.360000         15.740000         15.830000   \n",
       "75%        380.045000      370.895000         46.980000         45.690000   \n",
       "max       8285.640000    14043.060000       5315.590000       9324.660000   \n",
       "\n",
       "       loc_ic_t2t_mou_8  loc_ic_t2m_mou_6  loc_ic_t2m_mou_7  loc_ic_t2m_mou_8  \\\n",
       "count      66296.000000      67231.000000      67312.000000      66296.000000   \n",
       "mean          47.256388        107.152439        106.489856        108.154731   \n",
       "std          141.249368        168.455999        165.452459        166.223461   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            3.280000         17.390000         18.610000         18.940000   \n",
       "50%           16.040000         56.460000         56.930000         58.210000   \n",
       "75%           46.280000        132.020000        131.010000        134.380000   \n",
       "max        10696.230000       4450.740000       4455.830000       6274.190000   \n",
       "\n",
       "       loc_ic_t2f_mou_6  loc_ic_t2f_mou_7  loc_ic_t2f_mou_8  loc_ic_mou_6  \\\n",
       "count      67231.000000      67312.000000      66296.000000  67231.000000   \n",
       "mean          12.050672         12.563665         11.716763    167.255126   \n",
       "std           39.416076         43.495179         38.606895    252.576231   \n",
       "min            0.000000          0.000000          0.000000      0.000000   \n",
       "25%            0.000000          0.000000          0.000000     30.630000   \n",
       "50%            0.880000          0.910000          0.930000     92.430000   \n",
       "75%            8.140000          8.230000          8.090000    208.325000   \n",
       "max         1872.340000       1983.010000       1676.580000   7454.630000   \n",
       "\n",
       "       loc_ic_mou_7  loc_ic_mou_8  std_ic_t2t_mou_6  std_ic_t2t_mou_7  \\\n",
       "count  67312.000000  66296.000000      67231.000000      67312.000000   \n",
       "mean     166.945103    167.136761          9.476958          9.873468   \n",
       "std      254.688718    249.288410         51.664472         56.137824   \n",
       "min        0.000000      0.000000          0.000000          0.000000   \n",
       "25%       32.710000     32.810000          0.000000          0.000000   \n",
       "50%       92.510000     93.890000          0.000000          0.000000   \n",
       "75%      205.530000    208.060000          4.060000          4.180000   \n",
       "max     9669.910000  10830.160000       3336.380000       4708.710000   \n",
       "\n",
       "       std_ic_t2t_mou_8  std_ic_t2m_mou_6  std_ic_t2m_mou_7  std_ic_t2m_mou_8  \\\n",
       "count      66296.000000      67231.000000      67312.000000      66296.000000   \n",
       "mean           9.910217         20.734858         21.685359         21.089042   \n",
       "std           54.248186         80.294236         87.314510         81.534344   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            0.000000          0.000000          0.000000          0.000000   \n",
       "50%            0.000000          2.040000          2.060000          2.030000   \n",
       "75%            4.052500         14.960000         15.830000         15.310000   \n",
       "max         3930.240000       5647.160000       6141.880000       5512.760000   \n",
       "\n",
       "       std_ic_t2f_mou_6  std_ic_t2f_mou_7  std_ic_t2f_mou_8  std_ic_t2o_mou_6  \\\n",
       "count      67231.000000      67312.000000      66296.000000           67231.0   \n",
       "mean           2.146273          2.199395          2.075179               0.0   \n",
       "std           16.522232         16.171533         15.865403               0.0   \n",
       "min            0.000000          0.000000          0.000000               0.0   \n",
       "25%            0.000000          0.000000          0.000000               0.0   \n",
       "50%            0.000000          0.000000          0.000000               0.0   \n",
       "75%            0.000000          0.000000          0.000000               0.0   \n",
       "max         1351.110000       1136.080000       1394.890000               0.0   \n",
       "\n",
       "       std_ic_t2o_mou_7  std_ic_t2o_mou_8  std_ic_mou_6  std_ic_mou_7  \\\n",
       "count           67312.0           66296.0  67231.000000  67312.000000   \n",
       "mean                0.0               0.0     32.360632     33.760809   \n",
       "std                 0.0               0.0    104.381082    114.142230   \n",
       "min                 0.0               0.0      0.000000      0.000000   \n",
       "25%                 0.0               0.0      0.000000      0.000000   \n",
       "50%                 0.0               0.0      5.910000      5.980000   \n",
       "75%                 0.0               0.0     26.780000     28.160000   \n",
       "max                 0.0               0.0   5712.110000   6745.760000   \n",
       "\n",
       "       std_ic_mou_8  total_ic_mou_6  total_ic_mou_7  total_ic_mou_8  \\\n",
       "count  66296.000000    69999.000000    69999.000000    69999.000000   \n",
       "mean      33.077030      199.710640      201.878029      198.486034   \n",
       "std      108.469864      290.114823      296.771338      288.336731   \n",
       "min        0.000000        0.000000        0.000000        0.000000   \n",
       "25%        0.030000       38.640000       41.340000       38.290000   \n",
       "50%        5.830000      114.780000      116.330000      114.610000   \n",
       "75%       27.615000      251.070000      249.470000      249.710000   \n",
       "max     5658.740000     7716.140000     9699.010000    10830.380000   \n",
       "\n",
       "       spl_ic_mou_6  spl_ic_mou_7  spl_ic_mou_8  isd_ic_mou_6  isd_ic_mou_7  \\\n",
       "count  67231.000000  67312.000000  66296.000000  67231.000000  67312.000000   \n",
       "mean       0.061932      0.033371      0.040392      7.394167      8.171162   \n",
       "std        0.164823      0.137322      0.148417     60.951165     63.604165   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       19.760000     13.460000     16.860000   6789.410000   5289.540000   \n",
       "\n",
       "       isd_ic_mou_8   ic_others_6   ic_others_7   ic_others_8  \\\n",
       "count  66296.000000  67231.000000  67312.000000  66296.000000   \n",
       "mean       8.348424      0.854063      1.019680      0.963214   \n",
       "std       63.097570     12.149144     13.225373     11.697686   \n",
       "min        0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000   \n",
       "max     4127.010000   1362.940000   1495.940000   1209.860000   \n",
       "\n",
       "       total_rech_num_6  total_rech_num_7  total_rech_num_8  total_rech_amt_6  \\\n",
       "count      69999.000000      69999.000000      69999.000000      69999.000000   \n",
       "mean           7.566522          7.706667          7.224932        328.139788   \n",
       "std            7.041452          7.050614          7.195597        404.211068   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            3.000000          3.000000          3.000000        110.000000   \n",
       "50%            6.000000          6.000000          5.000000        229.000000   \n",
       "75%            9.000000         10.000000          9.000000        438.000000   \n",
       "max          170.000000        138.000000        138.000000      35190.000000   \n",
       "\n",
       "       total_rech_amt_7  total_rech_amt_8  max_rech_amt_6  max_rech_amt_7  \\\n",
       "count      69999.000000      69999.000000    69999.000000    69999.000000   \n",
       "mean         322.376363        323.846355      104.569265      104.137573   \n",
       "std          411.070120        426.181405      121.407701      120.782543   \n",
       "min            0.000000          0.000000        0.000000        0.000000   \n",
       "25%          100.000000         90.000000       30.000000       30.000000   \n",
       "50%          220.000000        225.000000      110.000000      110.000000   \n",
       "75%          430.000000        436.000000      120.000000      128.000000   \n",
       "max        40335.000000      45320.000000     4010.000000     3299.000000   \n",
       "\n",
       "       max_rech_amt_8  last_day_rch_amt_6  last_day_rch_amt_7  \\\n",
       "count    69999.000000        69999.000000        69999.000000   \n",
       "mean       107.540351           63.426949           59.294218   \n",
       "std        124.396750           97.954876           95.429492   \n",
       "min          0.000000            0.000000            0.000000   \n",
       "25%         30.000000            0.000000            0.000000   \n",
       "50%         98.000000           30.000000           30.000000   \n",
       "75%        144.000000          110.000000          110.000000   \n",
       "max       4449.000000         4010.000000         3100.000000   \n",
       "\n",
       "       last_day_rch_amt_8  total_rech_data_6  total_rech_data_7  \\\n",
       "count        69999.000000       17568.000000       17865.000000   \n",
       "mean            62.489478           2.467612           2.679989   \n",
       "std            101.996729           2.794610           3.073472   \n",
       "min              0.000000           1.000000           1.000000   \n",
       "25%              0.000000           1.000000           1.000000   \n",
       "50%             30.000000           1.000000           2.000000   \n",
       "75%            130.000000           3.000000           3.000000   \n",
       "max           4449.000000          61.000000          54.000000   \n",
       "\n",
       "       total_rech_data_8  max_rech_data_6  max_rech_data_7  max_rech_data_8  \\\n",
       "count       18417.000000     17568.000000     17865.000000     18417.000000   \n",
       "mean            2.652441       126.500000       126.402071       125.374925   \n",
       "std             3.101265       109.352573       109.459266       109.648799   \n",
       "min             1.000000         1.000000         1.000000         1.000000   \n",
       "25%             1.000000        25.000000        25.000000        25.000000   \n",
       "50%             1.000000       145.000000       145.000000       145.000000   \n",
       "75%             3.000000       177.000000       177.000000       179.000000   \n",
       "max            60.000000      1555.000000      1555.000000      1555.000000   \n",
       "\n",
       "       count_rech_2g_6  count_rech_2g_7  count_rech_2g_8  count_rech_3g_6  \\\n",
       "count     17568.000000     17865.000000     18417.000000     17568.000000   \n",
       "mean          1.865323         2.056311         2.016018         0.602288   \n",
       "std           2.566377         2.799916         2.728246         1.279297   \n",
       "min           0.000000         0.000000         0.000000         0.000000   \n",
       "25%           1.000000         1.000000         1.000000         0.000000   \n",
       "50%           1.000000         1.000000         1.000000         0.000000   \n",
       "75%           2.000000         2.000000         2.000000         1.000000   \n",
       "max          42.000000        48.000000        44.000000        29.000000   \n",
       "\n",
       "       count_rech_3g_7  count_rech_3g_8  av_rech_amt_data_6  \\\n",
       "count     17865.000000     18417.000000        17568.000000   \n",
       "mean          0.623678         0.636423          192.831096   \n",
       "std           1.401230         1.457058          190.623115   \n",
       "min           0.000000         0.000000            1.000000   \n",
       "25%           0.000000         0.000000           82.000000   \n",
       "50%           0.000000         0.000000          154.000000   \n",
       "75%           1.000000         1.000000          252.000000   \n",
       "max          34.000000        45.000000         5920.000000   \n",
       "\n",
       "       av_rech_amt_data_7  av_rech_amt_data_8   vol_2g_mb_6   vol_2g_mb_7  \\\n",
       "count        17865.000000        18417.000000  69999.000000  69999.000000   \n",
       "mean           201.455940          196.815792     51.773924     51.240204   \n",
       "std            198.346141          192.280532    212.513909    211.114667   \n",
       "min              1.000000            1.000000      0.000000      0.000000   \n",
       "25%             92.000000           84.000000      0.000000      0.000000   \n",
       "50%            154.000000          154.000000      0.000000      0.000000   \n",
       "75%            252.000000          252.000000      0.000000      0.000000   \n",
       "max           4365.000000         4076.000000  10285.900000   7873.550000   \n",
       "\n",
       "        vol_2g_mb_8   vol_3g_mb_6   vol_3g_mb_7   vol_3g_mb_8     arpu_3g_6  \\\n",
       "count  69999.000000  69999.000000  69999.000000  69999.000000  17568.000000   \n",
       "mean      50.127506    122.171882    128.934444    135.486541     90.069931   \n",
       "std      213.101403    554.869965    554.096072    568.310234    193.600413   \n",
       "min        0.000000      0.000000      0.000000      0.000000    -20.380000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.520000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000    122.070000   \n",
       "max    11117.610000  45735.400000  28144.120000  30036.060000   5054.370000   \n",
       "\n",
       "          arpu_3g_7     arpu_3g_8     arpu_2g_6     arpu_2g_7     arpu_2g_8  \\\n",
       "count  17865.000000  18417.000000  17568.000000  17865.000000  18417.000000   \n",
       "mean      89.115767     90.618564     86.863900     85.846074     86.348404   \n",
       "std      195.826990    189.907986    171.321203    178.067280    170.297094   \n",
       "min      -26.040000    -24.490000    -35.830000    -13.090000    -55.830000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.420000      0.840000     11.300000      8.800000      9.090000   \n",
       "75%      120.860000    122.070000    122.070000    122.070000    122.070000   \n",
       "max     4980.900000   3716.900000   5054.350000   4809.360000   3483.170000   \n",
       "\n",
       "       night_pck_user_6  night_pck_user_7  night_pck_user_8  monthly_2g_6  \\\n",
       "count      17568.000000      17865.000000      18417.000000  69999.000000   \n",
       "mean           0.025273          0.024069          0.021013      0.079287   \n",
       "std            0.156958          0.153269          0.143432      0.294719   \n",
       "min            0.000000          0.000000          0.000000      0.000000   \n",
       "25%            0.000000          0.000000          0.000000      0.000000   \n",
       "50%            0.000000          0.000000          0.000000      0.000000   \n",
       "75%            0.000000          0.000000          0.000000      0.000000   \n",
       "max            1.000000          1.000000          1.000000      4.000000   \n",
       "\n",
       "       monthly_2g_7  monthly_2g_8   sachet_2g_6   sachet_2g_7   sachet_2g_8  \\\n",
       "count  69999.000000  69999.000000  69999.000000  69999.000000  69999.000000   \n",
       "mean       0.083401      0.080930      0.388863      0.441406      0.449492   \n",
       "std        0.304802      0.299254      1.494206      1.651012      1.632450   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        5.000000      5.000000     42.000000     48.000000     44.000000   \n",
       "\n",
       "       monthly_3g_6  monthly_3g_7  monthly_3g_8   sachet_3g_6   sachet_3g_7  \\\n",
       "count  69999.000000  69999.000000  69999.000000  69999.000000  69999.000000   \n",
       "mean       0.075815      0.077730      0.081958      0.075344      0.081444   \n",
       "std        0.358905      0.383189      0.381821      0.573003      0.634547   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        9.000000     16.000000     16.000000     29.000000     33.000000   \n",
       "\n",
       "        sachet_3g_8     fb_user_6     fb_user_7     fb_user_8           aon  \\\n",
       "count  69999.000000  17568.000000  17865.000000  18417.000000  69999.000000   \n",
       "mean       0.085487      0.916325      0.909544      0.890319   1220.639709   \n",
       "std        0.680035      0.276907      0.286842      0.312501    952.426321   \n",
       "min        0.000000      0.000000      0.000000      0.000000    180.000000   \n",
       "25%        0.000000      1.000000      1.000000      1.000000    468.000000   \n",
       "50%        0.000000      1.000000      1.000000      1.000000    868.000000   \n",
       "75%        0.000000      1.000000      1.000000      1.000000   1813.000000   \n",
       "max       41.000000      1.000000      1.000000      1.000000   4337.000000   \n",
       "\n",
       "         aug_vbc_3g    jul_vbc_3g   jun_vbc_3g  churn_probability  \n",
       "count  69999.000000  69999.000000  69999.00000       69999.000000  \n",
       "mean      68.108597     65.935830     60.07674           0.101887  \n",
       "std      269.328659    267.899034    257.22681           0.302502  \n",
       "min        0.000000      0.000000      0.00000           0.000000  \n",
       "25%        0.000000      0.000000      0.00000           0.000000  \n",
       "50%        0.000000      0.000000      0.00000           0.000000  \n",
       "75%        0.000000      0.000000      0.00000           0.000000  \n",
       "max    12916.220000   9165.600000  11166.21000           1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling missing values in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>null</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>arpu_3g_6</th>\n",
       "      <td>74.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_rech_2g_6</th>\n",
       "      <td>74.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>night_pck_user_6</th>\n",
       "      <td>74.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arpu_2g_6</th>\n",
       "      <td>74.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_of_last_rech_data_6</th>\n",
       "      <td>74.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_day_rch_amt_8</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_2g_mb_6</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_2g_mb_7</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_2g_mb_8</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>churn_probability</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          null\n",
       "arpu_3g_6                 74.9\n",
       "count_rech_2g_6           74.9\n",
       "night_pck_user_6          74.9\n",
       "arpu_2g_6                 74.9\n",
       "date_of_last_rech_data_6  74.9\n",
       "...                        ...\n",
       "last_day_rch_amt_8         0.0\n",
       "vol_2g_mb_6                0.0\n",
       "vol_2g_mb_7                0.0\n",
       "vol_2g_mb_8                0.0\n",
       "churn_probability          0.0\n",
       "\n",
       "[172 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cheking percent of missing values in columns\n",
    "df_missing_columns = (round(((df.isnull().sum()/len(df.index))*100),2).to_frame('null')).sort_values('null', ascending=False)\n",
    "df_missing_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the columns having more than 30% missing values\n",
    "col_list_missing_30 = list(df_missing_columns.index[df_missing_columns['null'] > 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['arpu_3g_6', 'count_rech_2g_6', 'night_pck_user_6', 'arpu_2g_6', 'date_of_last_rech_data_6', 'total_rech_data_6', 'av_rech_amt_data_6', 'max_rech_data_6', 'count_rech_3g_6', 'fb_user_6', 'night_pck_user_7', 'date_of_last_rech_data_7', 'total_rech_data_7', 'max_rech_data_7', 'fb_user_7', 'count_rech_2g_7', 'count_rech_3g_7', 'arpu_3g_7', 'av_rech_amt_data_7', 'arpu_2g_7', 'count_rech_2g_8', 'av_rech_amt_data_8', 'night_pck_user_8', 'max_rech_data_8', 'total_rech_data_8', 'arpu_2g_8', 'arpu_3g_8', 'date_of_last_rech_data_8', 'fb_user_8', 'count_rech_3g_8'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Delete the columns having more than 30% missing values\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(col_list_missing_30, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5111\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5112\u001b[0m     labels: IndexLabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5120\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5121\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5122\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5123\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5256\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   5259\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5260\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5261\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5262\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5263\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5264\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5265\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   5266\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4547\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4549\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4589\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4591\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4592\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4594\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6699\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6699\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6700\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6701\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['arpu_3g_6', 'count_rech_2g_6', 'night_pck_user_6', 'arpu_2g_6', 'date_of_last_rech_data_6', 'total_rech_data_6', 'av_rech_amt_data_6', 'max_rech_data_6', 'count_rech_3g_6', 'fb_user_6', 'night_pck_user_7', 'date_of_last_rech_data_7', 'total_rech_data_7', 'max_rech_data_7', 'fb_user_7', 'count_rech_2g_7', 'count_rech_3g_7', 'arpu_3g_7', 'av_rech_amt_data_7', 'arpu_2g_7', 'count_rech_2g_8', 'av_rech_amt_data_8', 'night_pck_user_8', 'max_rech_data_8', 'total_rech_data_8', 'arpu_2g_8', 'arpu_3g_8', 'date_of_last_rech_data_8', 'fb_user_8', 'count_rech_3g_8'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Delete the columns having more than 30% missing values\n",
    "df = df.drop(col_list_missing_30, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Deleting the date columns as the date columns are not required in our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['last_date_of_month_6', 'last_date_of_month_7', 'last_date_of_month_8', 'date_of_last_rech_6', 'date_of_last_rech_7', 'date_of_last_rech_8']\n"
     ]
    }
   ],
   "source": [
    "# List the date columns\n",
    "date_cols = [k for k in df.columns.to_list() if 'date' in k]\n",
    "print(date_cols) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping date columns\n",
    "df = df.drop(date_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping circle_id column as this column has only one unique value. Hence there will be no impact of this column on the data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop circle_id column\n",
    "df = df.drop('circle_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69999, 135)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter high-value customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating column `avg_rech_amt_6_7` by summing up total recharge amount of month 6 and 7. Then taking the average of the sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_rech_amt_6_7'] = (df['total_rech_amt_6'] + df['total_rech_amt_7'])/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the 70th percentile of the avg_rech_amt_6_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df['avg_rech_amt_6_7'].quantile(0.7)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the customers, who have recharged more than or equal to X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>roam_ic_mou_7</th>\n",
       "      <th>roam_ic_mou_8</th>\n",
       "      <th>roam_og_mou_6</th>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <th>roam_og_mou_8</th>\n",
       "      <th>loc_og_t2t_mou_6</th>\n",
       "      <th>loc_og_t2t_mou_7</th>\n",
       "      <th>loc_og_t2t_mou_8</th>\n",
       "      <th>loc_og_t2m_mou_6</th>\n",
       "      <th>loc_og_t2m_mou_7</th>\n",
       "      <th>loc_og_t2m_mou_8</th>\n",
       "      <th>loc_og_t2f_mou_6</th>\n",
       "      <th>loc_og_t2f_mou_7</th>\n",
       "      <th>loc_og_t2f_mou_8</th>\n",
       "      <th>loc_og_t2c_mou_6</th>\n",
       "      <th>loc_og_t2c_mou_7</th>\n",
       "      <th>loc_og_t2c_mou_8</th>\n",
       "      <th>loc_og_mou_6</th>\n",
       "      <th>loc_og_mou_7</th>\n",
       "      <th>loc_og_mou_8</th>\n",
       "      <th>std_og_t2t_mou_6</th>\n",
       "      <th>std_og_t2t_mou_7</th>\n",
       "      <th>std_og_t2t_mou_8</th>\n",
       "      <th>std_og_t2m_mou_6</th>\n",
       "      <th>std_og_t2m_mou_7</th>\n",
       "      <th>std_og_t2m_mou_8</th>\n",
       "      <th>std_og_t2f_mou_6</th>\n",
       "      <th>std_og_t2f_mou_7</th>\n",
       "      <th>std_og_t2f_mou_8</th>\n",
       "      <th>std_og_t2c_mou_6</th>\n",
       "      <th>std_og_t2c_mou_7</th>\n",
       "      <th>std_og_t2c_mou_8</th>\n",
       "      <th>std_og_mou_6</th>\n",
       "      <th>std_og_mou_7</th>\n",
       "      <th>std_og_mou_8</th>\n",
       "      <th>isd_og_mou_6</th>\n",
       "      <th>isd_og_mou_7</th>\n",
       "      <th>isd_og_mou_8</th>\n",
       "      <th>spl_og_mou_6</th>\n",
       "      <th>spl_og_mou_7</th>\n",
       "      <th>spl_og_mou_8</th>\n",
       "      <th>og_others_6</th>\n",
       "      <th>og_others_7</th>\n",
       "      <th>og_others_8</th>\n",
       "      <th>total_og_mou_6</th>\n",
       "      <th>total_og_mou_7</th>\n",
       "      <th>total_og_mou_8</th>\n",
       "      <th>loc_ic_t2t_mou_6</th>\n",
       "      <th>loc_ic_t2t_mou_7</th>\n",
       "      <th>loc_ic_t2t_mou_8</th>\n",
       "      <th>loc_ic_t2m_mou_6</th>\n",
       "      <th>loc_ic_t2m_mou_7</th>\n",
       "      <th>loc_ic_t2m_mou_8</th>\n",
       "      <th>loc_ic_t2f_mou_6</th>\n",
       "      <th>loc_ic_t2f_mou_7</th>\n",
       "      <th>loc_ic_t2f_mou_8</th>\n",
       "      <th>loc_ic_mou_6</th>\n",
       "      <th>loc_ic_mou_7</th>\n",
       "      <th>loc_ic_mou_8</th>\n",
       "      <th>std_ic_t2t_mou_6</th>\n",
       "      <th>std_ic_t2t_mou_7</th>\n",
       "      <th>std_ic_t2t_mou_8</th>\n",
       "      <th>std_ic_t2m_mou_6</th>\n",
       "      <th>std_ic_t2m_mou_7</th>\n",
       "      <th>std_ic_t2m_mou_8</th>\n",
       "      <th>std_ic_t2f_mou_6</th>\n",
       "      <th>std_ic_t2f_mou_7</th>\n",
       "      <th>std_ic_t2f_mou_8</th>\n",
       "      <th>std_ic_t2o_mou_6</th>\n",
       "      <th>std_ic_t2o_mou_7</th>\n",
       "      <th>std_ic_t2o_mou_8</th>\n",
       "      <th>std_ic_mou_6</th>\n",
       "      <th>std_ic_mou_7</th>\n",
       "      <th>std_ic_mou_8</th>\n",
       "      <th>total_ic_mou_6</th>\n",
       "      <th>total_ic_mou_7</th>\n",
       "      <th>total_ic_mou_8</th>\n",
       "      <th>spl_ic_mou_6</th>\n",
       "      <th>spl_ic_mou_7</th>\n",
       "      <th>spl_ic_mou_8</th>\n",
       "      <th>isd_ic_mou_6</th>\n",
       "      <th>isd_ic_mou_7</th>\n",
       "      <th>isd_ic_mou_8</th>\n",
       "      <th>ic_others_6</th>\n",
       "      <th>ic_others_7</th>\n",
       "      <th>ic_others_8</th>\n",
       "      <th>total_rech_num_6</th>\n",
       "      <th>total_rech_num_7</th>\n",
       "      <th>total_rech_num_8</th>\n",
       "      <th>total_rech_amt_6</th>\n",
       "      <th>total_rech_amt_7</th>\n",
       "      <th>total_rech_amt_8</th>\n",
       "      <th>max_rech_amt_6</th>\n",
       "      <th>max_rech_amt_7</th>\n",
       "      <th>max_rech_amt_8</th>\n",
       "      <th>last_day_rch_amt_6</th>\n",
       "      <th>last_day_rch_amt_7</th>\n",
       "      <th>last_day_rch_amt_8</th>\n",
       "      <th>vol_2g_mb_6</th>\n",
       "      <th>vol_2g_mb_7</th>\n",
       "      <th>vol_2g_mb_8</th>\n",
       "      <th>vol_3g_mb_6</th>\n",
       "      <th>vol_3g_mb_7</th>\n",
       "      <th>vol_3g_mb_8</th>\n",
       "      <th>monthly_2g_6</th>\n",
       "      <th>monthly_2g_7</th>\n",
       "      <th>monthly_2g_8</th>\n",
       "      <th>sachet_2g_6</th>\n",
       "      <th>sachet_2g_7</th>\n",
       "      <th>sachet_2g_8</th>\n",
       "      <th>monthly_3g_6</th>\n",
       "      <th>monthly_3g_7</th>\n",
       "      <th>monthly_3g_8</th>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>churn_probability</th>\n",
       "      <th>avg_rech_amt_6_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>439.919</td>\n",
       "      <td>397.946</td>\n",
       "      <td>392.024</td>\n",
       "      <td>244.46</td>\n",
       "      <td>108.31</td>\n",
       "      <td>42.98</td>\n",
       "      <td>571.98</td>\n",
       "      <td>727.91</td>\n",
       "      <td>644.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.86</td>\n",
       "      <td>3.98</td>\n",
       "      <td>44.01</td>\n",
       "      <td>13.93</td>\n",
       "      <td>51.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>44.01</td>\n",
       "      <td>21.79</td>\n",
       "      <td>55.23</td>\n",
       "      <td>244.46</td>\n",
       "      <td>100.44</td>\n",
       "      <td>38.99</td>\n",
       "      <td>527.96</td>\n",
       "      <td>713.98</td>\n",
       "      <td>593.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>772.43</td>\n",
       "      <td>814.43</td>\n",
       "      <td>632.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>816.44</td>\n",
       "      <td>836.23</td>\n",
       "      <td>687.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.06</td>\n",
       "      <td>26.93</td>\n",
       "      <td>25.68</td>\n",
       "      <td>23.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26.93</td>\n",
       "      <td>26.21</td>\n",
       "      <td>24.53</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.33</td>\n",
       "      <td>8.64</td>\n",
       "      <td>2.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.56</td>\n",
       "      <td>9.13</td>\n",
       "      <td>2.46</td>\n",
       "      <td>34.49</td>\n",
       "      <td>35.34</td>\n",
       "      <td>26.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>521</td>\n",
       "      <td>418</td>\n",
       "      <td>365</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>469.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>580.549</td>\n",
       "      <td>377.294</td>\n",
       "      <td>338.286</td>\n",
       "      <td>10.43</td>\n",
       "      <td>24.99</td>\n",
       "      <td>194.43</td>\n",
       "      <td>317.11</td>\n",
       "      <td>341.79</td>\n",
       "      <td>197.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.43</td>\n",
       "      <td>24.99</td>\n",
       "      <td>194.43</td>\n",
       "      <td>313.76</td>\n",
       "      <td>330.88</td>\n",
       "      <td>185.88</td>\n",
       "      <td>3.26</td>\n",
       "      <td>10.91</td>\n",
       "      <td>4.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>327.46</td>\n",
       "      <td>366.79</td>\n",
       "      <td>385.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>327.64</td>\n",
       "      <td>366.79</td>\n",
       "      <td>391.53</td>\n",
       "      <td>13.86</td>\n",
       "      <td>20.18</td>\n",
       "      <td>335.43</td>\n",
       "      <td>219.31</td>\n",
       "      <td>754.24</td>\n",
       "      <td>285.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.93</td>\n",
       "      <td>8.88</td>\n",
       "      <td>233.18</td>\n",
       "      <td>776.36</td>\n",
       "      <td>629.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>233.18</td>\n",
       "      <td>777.39</td>\n",
       "      <td>629.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>654</td>\n",
       "      <td>400</td>\n",
       "      <td>652</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>250</td>\n",
       "      <td>260.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>354.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>527.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1130.948</td>\n",
       "      <td>905.506</td>\n",
       "      <td>479.762</td>\n",
       "      <td>859.53</td>\n",
       "      <td>372.71</td>\n",
       "      <td>0.89</td>\n",
       "      <td>293.46</td>\n",
       "      <td>450.11</td>\n",
       "      <td>386.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>859.53</td>\n",
       "      <td>372.71</td>\n",
       "      <td>0.89</td>\n",
       "      <td>79.79</td>\n",
       "      <td>424.63</td>\n",
       "      <td>378.01</td>\n",
       "      <td>11.58</td>\n",
       "      <td>25.43</td>\n",
       "      <td>8.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>950.91</td>\n",
       "      <td>822.78</td>\n",
       "      <td>387.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>202.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>202.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1152.99</td>\n",
       "      <td>822.83</td>\n",
       "      <td>387.81</td>\n",
       "      <td>233.28</td>\n",
       "      <td>117.63</td>\n",
       "      <td>30.39</td>\n",
       "      <td>123.78</td>\n",
       "      <td>278.49</td>\n",
       "      <td>148.83</td>\n",
       "      <td>34.31</td>\n",
       "      <td>52.08</td>\n",
       "      <td>23.66</td>\n",
       "      <td>391.38</td>\n",
       "      <td>448.21</td>\n",
       "      <td>202.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>207.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>207.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>598.54</td>\n",
       "      <td>448.36</td>\n",
       "      <td>203.29</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.4</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>1420</td>\n",
       "      <td>990</td>\n",
       "      <td>494</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>144</td>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>371.974</td>\n",
       "      <td>352.069</td>\n",
       "      <td>240.449</td>\n",
       "      <td>93.18</td>\n",
       "      <td>38.29</td>\n",
       "      <td>29.86</td>\n",
       "      <td>531.19</td>\n",
       "      <td>507.76</td>\n",
       "      <td>222.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.18</td>\n",
       "      <td>38.29</td>\n",
       "      <td>29.86</td>\n",
       "      <td>159.29</td>\n",
       "      <td>219.44</td>\n",
       "      <td>99.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>252.48</td>\n",
       "      <td>257.74</td>\n",
       "      <td>129.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>371.89</td>\n",
       "      <td>288.31</td>\n",
       "      <td>121.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>371.89</td>\n",
       "      <td>288.31</td>\n",
       "      <td>121.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>624.38</td>\n",
       "      <td>546.06</td>\n",
       "      <td>251.89</td>\n",
       "      <td>52.49</td>\n",
       "      <td>37.84</td>\n",
       "      <td>19.14</td>\n",
       "      <td>170.61</td>\n",
       "      <td>106.71</td>\n",
       "      <td>150.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.13</td>\n",
       "      <td>223.11</td>\n",
       "      <td>146.09</td>\n",
       "      <td>171.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.96</td>\n",
       "      <td>9.54</td>\n",
       "      <td>21.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.96</td>\n",
       "      <td>9.54</td>\n",
       "      <td>21.93</td>\n",
       "      <td>230.08</td>\n",
       "      <td>155.64</td>\n",
       "      <td>192.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>440</td>\n",
       "      <td>427</td>\n",
       "      <td>240</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>30</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>433.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>362.951</td>\n",
       "      <td>321.763</td>\n",
       "      <td>689.603</td>\n",
       "      <td>193.71</td>\n",
       "      <td>124.53</td>\n",
       "      <td>197.54</td>\n",
       "      <td>423.21</td>\n",
       "      <td>184.88</td>\n",
       "      <td>556.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.81</td>\n",
       "      <td>75.01</td>\n",
       "      <td>81.86</td>\n",
       "      <td>164.39</td>\n",
       "      <td>115.48</td>\n",
       "      <td>229.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.01</td>\n",
       "      <td>217.53</td>\n",
       "      <td>190.49</td>\n",
       "      <td>311.91</td>\n",
       "      <td>143.89</td>\n",
       "      <td>49.51</td>\n",
       "      <td>115.68</td>\n",
       "      <td>255.49</td>\n",
       "      <td>64.99</td>\n",
       "      <td>301.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>399.39</td>\n",
       "      <td>114.51</td>\n",
       "      <td>416.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.40</td>\n",
       "      <td>25.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>616.93</td>\n",
       "      <td>309.41</td>\n",
       "      <td>754.16</td>\n",
       "      <td>113.76</td>\n",
       "      <td>114.98</td>\n",
       "      <td>95.31</td>\n",
       "      <td>230.24</td>\n",
       "      <td>180.11</td>\n",
       "      <td>319.01</td>\n",
       "      <td>26.71</td>\n",
       "      <td>2.01</td>\n",
       "      <td>11.24</td>\n",
       "      <td>370.73</td>\n",
       "      <td>297.11</td>\n",
       "      <td>425.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.15</td>\n",
       "      <td>25.88</td>\n",
       "      <td>17.49</td>\n",
       "      <td>9.89</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.64</td>\n",
       "      <td>19.68</td>\n",
       "      <td>10.04</td>\n",
       "      <td>401.39</td>\n",
       "      <td>319.08</td>\n",
       "      <td>454.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.01</td>\n",
       "      <td>2.28</td>\n",
       "      <td>19.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>330</td>\n",
       "      <td>480</td>\n",
       "      <td>730</td>\n",
       "      <td>110</td>\n",
       "      <td>150</td>\n",
       "      <td>130</td>\n",
       "      <td>110</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>405.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  loc_og_t2o_mou  std_og_t2o_mou  loc_ic_t2o_mou    arpu_6   arpu_7  \\\n",
       "12  12             0.0             0.0             0.0   439.919  397.946   \n",
       "15  15             0.0             0.0             0.0   580.549  377.294   \n",
       "23  23             0.0             0.0             0.0  1130.948  905.506   \n",
       "24  24             0.0             0.0             0.0   371.974  352.069   \n",
       "25  25             0.0             0.0             0.0   362.951  321.763   \n",
       "\n",
       "     arpu_8  onnet_mou_6  onnet_mou_7  onnet_mou_8  offnet_mou_6  \\\n",
       "12  392.024       244.46       108.31        42.98        571.98   \n",
       "15  338.286        10.43        24.99       194.43        317.11   \n",
       "23  479.762       859.53       372.71         0.89        293.46   \n",
       "24  240.449        93.18        38.29        29.86        531.19   \n",
       "25  689.603       193.71       124.53       197.54        423.21   \n",
       "\n",
       "    offnet_mou_7  offnet_mou_8  roam_ic_mou_6  roam_ic_mou_7  roam_ic_mou_8  \\\n",
       "12        727.91        644.43            0.0            0.0            0.0   \n",
       "15        341.79        197.09            0.0            0.0            0.0   \n",
       "23        450.11        386.91            0.0            0.0            0.0   \n",
       "24        507.76        222.03            0.0            0.0            0.0   \n",
       "25        184.88        556.61            0.0            0.0            0.0   \n",
       "\n",
       "    roam_og_mou_6  roam_og_mou_7  roam_og_mou_8  loc_og_t2t_mou_6  \\\n",
       "12            0.0            0.0            0.0              0.00   \n",
       "15            0.0            0.0            0.0             10.43   \n",
       "23            0.0            0.0            0.0            859.53   \n",
       "24            0.0            0.0            0.0             93.18   \n",
       "25            0.0            0.0            0.0             49.81   \n",
       "\n",
       "    loc_og_t2t_mou_7  loc_og_t2t_mou_8  loc_og_t2m_mou_6  loc_og_t2m_mou_7  \\\n",
       "12              7.86              3.98             44.01             13.93   \n",
       "15             24.99            194.43            313.76            330.88   \n",
       "23            372.71              0.89             79.79            424.63   \n",
       "24             38.29             29.86            159.29            219.44   \n",
       "25             75.01             81.86            164.39            115.48   \n",
       "\n",
       "    loc_og_t2m_mou_8  loc_og_t2f_mou_6  loc_og_t2f_mou_7  loc_og_t2f_mou_8  \\\n",
       "12             51.24              0.00              0.00              0.00   \n",
       "15            185.88              3.26             10.91              4.94   \n",
       "23            378.01             11.58             25.43              8.88   \n",
       "24             99.86              0.00              0.00              0.00   \n",
       "25            229.68              3.31              0.00              0.36   \n",
       "\n",
       "    loc_og_t2c_mou_6  loc_og_t2c_mou_7  loc_og_t2c_mou_8  loc_og_mou_6  \\\n",
       "12               0.0               0.0              0.00         44.01   \n",
       "15               0.0               0.0              0.00        327.46   \n",
       "23               0.0               0.0              0.00        950.91   \n",
       "24               0.0               0.0              0.36        252.48   \n",
       "25               0.0               0.0              7.01        217.53   \n",
       "\n",
       "    loc_og_mou_7  loc_og_mou_8  std_og_t2t_mou_6  std_og_t2t_mou_7  \\\n",
       "12         21.79         55.23            244.46            100.44   \n",
       "15        366.79        385.26              0.00              0.00   \n",
       "23        822.78        387.79              0.00              0.00   \n",
       "24        257.74        129.73              0.00              0.00   \n",
       "25        190.49        311.91            143.89             49.51   \n",
       "\n",
       "    std_og_t2t_mou_8  std_og_t2m_mou_6  std_og_t2m_mou_7  std_og_t2m_mou_8  \\\n",
       "12             38.99            527.96            713.98            593.18   \n",
       "15              0.00              0.00              0.00              0.00   \n",
       "23              0.00            202.08              0.00              0.00   \n",
       "24              0.00            371.89            288.31            121.79   \n",
       "25            115.68            255.49             64.99            301.31   \n",
       "\n",
       "    std_og_t2f_mou_6  std_og_t2f_mou_7  std_og_t2f_mou_8  std_og_t2c_mou_6  \\\n",
       "12               0.0               0.0              0.00               0.0   \n",
       "15               0.0               0.0              6.26               0.0   \n",
       "23               0.0               0.0              0.00               0.0   \n",
       "24               0.0               0.0              0.00               0.0   \n",
       "25               0.0               0.0              0.00               0.0   \n",
       "\n",
       "    std_og_t2c_mou_7  std_og_t2c_mou_8  std_og_mou_6  std_og_mou_7  \\\n",
       "12               0.0               0.0        772.43        814.43   \n",
       "15               0.0               0.0          0.00          0.00   \n",
       "23               0.0               0.0        202.08          0.00   \n",
       "24               0.0               0.0        371.89        288.31   \n",
       "25               0.0               0.0        399.39        114.51   \n",
       "\n",
       "    std_og_mou_8  isd_og_mou_6  isd_og_mou_7  isd_og_mou_8  spl_og_mou_6  \\\n",
       "12        632.18           0.0           0.0           0.0          0.00   \n",
       "15          6.26           0.0           0.0           0.0          0.08   \n",
       "23          0.00           0.0           0.0           0.0          0.00   \n",
       "24        121.79           0.0           0.0           0.0          0.00   \n",
       "25        416.99           0.0           0.0           0.0          0.00   \n",
       "\n",
       "    spl_og_mou_7  spl_og_mou_8  og_others_6  og_others_7  og_others_8  \\\n",
       "12          0.00          0.00          0.0          0.0          0.0   \n",
       "15          0.00          0.00          0.1          0.0          0.0   \n",
       "23          0.05          0.01          0.0          0.0          0.0   \n",
       "24          0.00          0.36          0.0          0.0          0.0   \n",
       "25          4.40         25.24          0.0          0.0          0.0   \n",
       "\n",
       "    total_og_mou_6  total_og_mou_7  total_og_mou_8  loc_ic_t2t_mou_6  \\\n",
       "12          816.44          836.23          687.41              0.00   \n",
       "15          327.64          366.79          391.53             13.86   \n",
       "23         1152.99          822.83          387.81            233.28   \n",
       "24          624.38          546.06          251.89             52.49   \n",
       "25          616.93          309.41          754.16            113.76   \n",
       "\n",
       "    loc_ic_t2t_mou_7  loc_ic_t2t_mou_8  loc_ic_t2m_mou_6  loc_ic_t2m_mou_7  \\\n",
       "12              0.53              1.06             26.93             25.68   \n",
       "15             20.18            335.43            219.31            754.24   \n",
       "23            117.63             30.39            123.78            278.49   \n",
       "24             37.84             19.14            170.61            106.71   \n",
       "25            114.98             95.31            230.24            180.11   \n",
       "\n",
       "    loc_ic_t2m_mou_8  loc_ic_t2f_mou_6  loc_ic_t2f_mou_7  loc_ic_t2f_mou_8  \\\n",
       "12             23.46              0.00              0.00              0.00   \n",
       "15            285.63              0.00              1.93              8.88   \n",
       "23            148.83             34.31             52.08             23.66   \n",
       "24            150.73              0.00              1.53              1.13   \n",
       "25            319.01             26.71              2.01             11.24   \n",
       "\n",
       "    loc_ic_mou_6  loc_ic_mou_7  loc_ic_mou_8  std_ic_t2t_mou_6  \\\n",
       "12         26.93         26.21         24.53              0.23   \n",
       "15        233.18        776.36        629.94              0.00   \n",
       "23        391.38        448.21        202.89              0.00   \n",
       "24        223.11        146.09        171.01              0.00   \n",
       "25        370.73        297.11        425.58              0.00   \n",
       "\n",
       "    std_ic_t2t_mou_7  std_ic_t2t_mou_8  std_ic_t2m_mou_6  std_ic_t2m_mou_7  \\\n",
       "12              0.00              0.00              7.33              8.64   \n",
       "15              0.00              0.00              0.00              0.00   \n",
       "23              0.00              0.00            207.03              0.00   \n",
       "24              0.00              0.00              6.96              9.54   \n",
       "25              2.18              0.15             25.88             17.49   \n",
       "\n",
       "    std_ic_t2m_mou_8  std_ic_t2f_mou_6  std_ic_t2f_mou_7  std_ic_t2f_mou_8  \\\n",
       "12              2.46              0.00              0.48               0.0   \n",
       "15              0.00              0.00              1.03               0.0   \n",
       "23              0.00              0.00              0.00               0.0   \n",
       "24             21.93              0.00              0.00               0.0   \n",
       "25              9.89              0.76              0.00               0.0   \n",
       "\n",
       "    std_ic_t2o_mou_6  std_ic_t2o_mou_7  std_ic_t2o_mou_8  std_ic_mou_6  \\\n",
       "12               0.0               0.0               0.0          7.56   \n",
       "15               0.0               0.0               0.0          0.00   \n",
       "23               0.0               0.0               0.0        207.03   \n",
       "24               0.0               0.0               0.0          6.96   \n",
       "25               0.0               0.0               0.0         26.64   \n",
       "\n",
       "    std_ic_mou_7  std_ic_mou_8  total_ic_mou_6  total_ic_mou_7  \\\n",
       "12          9.13          2.46           34.49           35.34   \n",
       "15          1.03          0.00          233.18          777.39   \n",
       "23          0.00          0.00          598.54          448.36   \n",
       "24          9.54         21.93          230.08          155.64   \n",
       "25         19.68         10.04          401.39          319.08   \n",
       "\n",
       "    total_ic_mou_8  spl_ic_mou_6  spl_ic_mou_7  spl_ic_mou_8  isd_ic_mou_6  \\\n",
       "12           26.99          0.00           0.0           0.0          0.00   \n",
       "15          629.94          0.00           0.0           0.0          0.00   \n",
       "23          203.29          0.13           0.0           0.0          0.00   \n",
       "24          192.94          0.00           0.0           0.0          0.00   \n",
       "25          454.91          0.00           0.0           0.0          4.01   \n",
       "\n",
       "    isd_ic_mou_7  isd_ic_mou_8  ic_others_6  ic_others_7  ic_others_8  \\\n",
       "12          0.00          0.00          0.0         0.00          0.0   \n",
       "15          0.00          0.00          0.0         0.00          0.0   \n",
       "23          0.00          0.00          0.0         0.15          0.4   \n",
       "24          0.00          0.00          0.0         0.00          0.0   \n",
       "25          2.28         19.28          0.0         0.00          0.0   \n",
       "\n",
       "    total_rech_num_6  total_rech_num_7  total_rech_num_8  total_rech_amt_6  \\\n",
       "12                15                10                20               521   \n",
       "15                 5                 3                 4               654   \n",
       "23                26                19                10              1420   \n",
       "24                 7                 7                10               440   \n",
       "25                 8                 5                11               330   \n",
       "\n",
       "    total_rech_amt_7  total_rech_amt_8  max_rech_amt_6  max_rech_amt_7  \\\n",
       "12               418               365             110             110   \n",
       "15               400               652             250             250   \n",
       "23               990               494             110             110   \n",
       "24               427               240             110             110   \n",
       "25               480               730             110             150   \n",
       "\n",
       "    max_rech_amt_8  last_day_rch_amt_6  last_day_rch_amt_7  \\\n",
       "12              50                 110                   0   \n",
       "15             250                   0                 150   \n",
       "23             144                 110                  50   \n",
       "24              30                 110                   0   \n",
       "25             130                 110                 150   \n",
       "\n",
       "    last_day_rch_amt_8  vol_2g_mb_6  vol_2g_mb_7  vol_2g_mb_8  vol_3g_mb_6  \\\n",
       "12                   0         0.00          0.0         0.00          0.0   \n",
       "15                 250       260.42          0.0       354.35          0.0   \n",
       "23                  30         0.00          0.0         0.00          0.0   \n",
       "24                  30         0.04          0.0         0.00          0.0   \n",
       "25                  50         0.00          0.0         0.00          0.0   \n",
       "\n",
       "    vol_3g_mb_7  vol_3g_mb_8  monthly_2g_6  monthly_2g_7  monthly_2g_8  \\\n",
       "12          0.0          0.0             0             0             0   \n",
       "15          0.0          0.0             1             0             1   \n",
       "23          0.0          0.0             0             0             0   \n",
       "24          0.0          0.0             0             0             0   \n",
       "25          0.0          0.0             0             0             0   \n",
       "\n",
       "    sachet_2g_6  sachet_2g_7  sachet_2g_8  monthly_3g_6  monthly_3g_7  \\\n",
       "12            0            0            0             0             0   \n",
       "15            0            0            0             0             0   \n",
       "23            0            0            0             0             0   \n",
       "24            1            2            1             0             0   \n",
       "25            0            0            0             0             0   \n",
       "\n",
       "    monthly_3g_8  sachet_3g_6  sachet_3g_7  sachet_3g_8   aon  aug_vbc_3g  \\\n",
       "12             0            0            0            0   322         0.0   \n",
       "15             0            0            0            0   602         0.0   \n",
       "23             0            0            0            0   455         0.0   \n",
       "24             0            0            0            0  1219         0.0   \n",
       "25             0            0            0            0  2831         0.0   \n",
       "\n",
       "    jul_vbc_3g  jun_vbc_3g  churn_probability  avg_rech_amt_6_7  \n",
       "12         0.0         0.0                  0             469.5  \n",
       "15         0.0         0.0                  0             527.0  \n",
       "23         0.0         0.0                  0            1205.0  \n",
       "24         0.0         0.0                  0             433.5  \n",
       "25         0.0         0.0                  0             405.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['avg_rech_amt_6_7'] >= X]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21018, 136)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have around ***~30K*** rows after filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling missing values in rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 136)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the rows having more than 50% missing values\n",
    "df_missing_rows_50 = df[(df.isnull().sum(axis=1)) > (len(df.columns)//2)]\n",
    "df_missing_rows_50.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20938, 136)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deleting the rows having more than 50% missing values\n",
    "df = df.drop(df_missing_rows_50.index)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>null</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loc_og_mou_8</th>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2t_mou_8</th>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2f_mou_8</th>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_t2o_mou_8</th>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2c_mou_8</th>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rech_amt_8</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_rech_amt_6</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_rech_amt_7</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_rech_amt_8</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_rech_amt_6_7</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  null\n",
       "loc_og_mou_8      2.75\n",
       "loc_og_t2t_mou_8  2.75\n",
       "loc_og_t2f_mou_8  2.75\n",
       "std_ic_t2o_mou_8  2.75\n",
       "loc_og_t2c_mou_8  2.75\n",
       "...                ...\n",
       "total_rech_amt_8  0.00\n",
       "max_rech_amt_6    0.00\n",
       "max_rech_amt_7    0.00\n",
       "max_rech_amt_8    0.00\n",
       "avg_rech_amt_6_7  0.00\n",
       "\n",
       "[136 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the missing values in columns again\n",
    "df_missing_columns = (round(((df.isnull().sum()/len(df.index))*100),2).to_frame('null')).sort_values('null', ascending=False)\n",
    "df_missing_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like MOU for all the types of calls for the month of September (9) have missing values together for any particular record.\n",
    "\n",
    "Lets check the records for the MOU for Sep(9), in which these coulmns have missing values together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Listing the columns of MOU Sep(9)  \n",
    "print(((df_missing_columns[df_missing_columns['null'] == 3]).index).to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'loc_ic_t2f_mou_9'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'loc_ic_t2f_mou_9'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Creating a dataframe with the condition, in which MOU for Sep(9) are null\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_null_mou_9 \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloc_ic_t2f_mou_9\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroam_og_mou_9\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd_ic_t2m_mou_9\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()) \u001b[38;5;241m&\u001b[39m\n\u001b[0;32m      3\u001b[0m   (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloc_og_t2t_mou_9\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd_ic_t2t_mou_9\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloc_og_t2f_mou_9\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloc_ic_mou_9\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()) \u001b[38;5;241m&\u001b[39m\n\u001b[0;32m      4\u001b[0m   (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd_og_t2t_mou_9\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroam_ic_mou_9\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()) \u001b[38;5;241m&\u001b[39m\n\u001b[0;32m      5\u001b[0m   (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd_og_t2m_mou_9\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloc_ic_t2t_mou_9\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd_og_t2f_mou_9\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()) \u001b[38;5;241m&\u001b[39m \n\u001b[0;32m      6\u001b[0m   (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd_og_t2c_mou_9\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mog_others_9\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd_og_mou_9\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspl_og_mou_9\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()) \u001b[38;5;241m&\u001b[39m \n\u001b[0;32m      7\u001b[0m   (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd_ic_t2f_mou_9\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124misd_og_mou_9\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd_ic_mou_9\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moffnet_mou_9\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()) \u001b[38;5;241m&\u001b[39m \n\u001b[0;32m      8\u001b[0m   (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124misd_ic_mou_9\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mic_others_9\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd_ic_t2o_mou_9\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124monnet_mou_9\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()) \u001b[38;5;241m&\u001b[39m \n\u001b[0;32m      9\u001b[0m   (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspl_ic_mou_9\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull())]\n\u001b[0;32m     11\u001b[0m df_null_mou_9\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'loc_ic_t2f_mou_9'"
     ]
    }
   ],
   "source": [
    "# Creating a dataframe with the condition, in which MOU for Sep(9) are null\n",
    "df_null_mou_9 = df[(df['loc_ic_t2f_mou_9'].isnull()) & (df['roam_og_mou_9'].isnull()) & (df['std_ic_t2m_mou_9'].isnull()) &\n",
    "  (df['loc_og_t2t_mou_9'].isnull()) & (df['std_ic_t2t_mou_9'].isnull()) & (df['loc_og_t2f_mou_9'].isnull()) & (df['loc_ic_mou_9'].isnull()) &\n",
    "  (df['std_og_t2t_mou_9'].isnull()) & (df['roam_ic_mou_9'].isnull()) &\n",
    "  (df['std_og_t2m_mou_9'].isnull()) & (df['loc_ic_t2t_mou_9'].isnull()) & (df['std_og_t2f_mou_9'].isnull()) & \n",
    "  (df['std_og_t2c_mou_9'].isnull()) & (df['og_others_9'].isnull()) & (df['std_og_mou_9'].isnull()) & (df['spl_og_mou_9'].isnull()) & \n",
    "  (df['std_ic_t2f_mou_9'].isnull()) & (df['isd_og_mou_9'].isnull()) & (df['std_ic_mou_9'].isnull()) & (df['offnet_mou_9'].isnull()) & \n",
    "  (df['isd_ic_mou_9'].isnull()) & (df['ic_others_9'].isnull()) & (df['std_ic_t2o_mou_9'].isnull()) & (df['onnet_mou_9'].isnull()) & \n",
    "  (df['spl_ic_mou_9'].isnull())]\n",
    "\n",
    "df_null_mou_9.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'loc_ic_t2m_mou_9 '",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'loc_ic_t2m_mou_9 '",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloc_ic_t2m_mou_9 \u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'loc_ic_t2m_mou_9 '"
     ]
    }
   ],
   "source": [
    "df['loc_ic_t2m_mou_9 ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_null_mou_9' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_null_mou_9\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_null_mou_9' is not defined"
     ]
    }
   ],
   "source": [
    "df_null_mou_9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the records for which MOU for Sep(9) are null\n",
    "df = df.drop(df_null_mou_9.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Again Cheking percent of missing values in columns\n",
    "df_missing_columns = (round(((df.isnull().sum()/len(df.index))*100),2).to_frame('null')).sort_values('null', ascending=False)\n",
    "df_missing_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like MOU for all the types of calls for the month of Aug (8) have missing values together for any particular record.\n",
    "\n",
    "Lets check the records for the MOU for Aug(8), in which these coulmns have missing values together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing the columns of MOU Aug(8)\n",
    "print(((df_missing_columns[df_missing_columns['null'] == 0.55]).index).to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe with the condition, in which MOU for Aug(8) are null\n",
    "df_null_mou_8 = df[(df['loc_og_t2m_mou_8'].isnull()) & (df['loc_ic_t2f_mou_8'].isnull()) & (df['roam_og_mou_8'].isnull()) & (df['std_ic_t2m_mou_8'].isnull()) &\n",
    "  (df['loc_og_t2t_mou_8'].isnull()) & (df['std_ic_t2t_mou_8'].isnull()) & (df['loc_og_t2f_mou_8'].isnull()) & (df['loc_ic_mou_8'].isnull()) &\n",
    "  (df['loc_og_t2c_mou_8'].isnull()) & (df['loc_og_mou_8'].isnull()) & (df['std_og_t2t_mou_8'].isnull()) & (df['roam_ic_mou_8'].isnull()) &\n",
    "  (df['loc_ic_t2m_mou_8'].isnull()) & (df['std_og_t2m_mou_8'].isnull()) & (df['loc_ic_t2t_mou_8'].isnull()) & (df['std_og_t2f_mou_8'].isnull()) & \n",
    "  (df['std_og_t2c_mou_8'].isnull()) & (df['og_others_8'].isnull()) & (df['std_og_mou_8'].isnull()) & (df['spl_og_mou_8'].isnull()) & \n",
    "  (df['std_ic_t2f_mou_8'].isnull()) & (df['isd_og_mou_8'].isnull()) & (df['std_ic_mou_8'].isnull()) & (df['offnet_mou_8'].isnull()) & \n",
    "  (df['isd_ic_mou_8'].isnull()) & (df['ic_others_8'].isnull()) & (df['std_ic_t2o_mou_8'].isnull()) & (df['onnet_mou_8'].isnull()) & \n",
    "  (df['spl_ic_mou_8'].isnull())]\n",
    "\n",
    "df_null_mou_8.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the records for which MOU for Aug(8) are null\n",
    "df = df.drop(df_null_mou_8.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Again cheking percent of missing values in columns\n",
    "df_missing_columns = (round(((df.isnull().sum()/len(df.index))*100),2).to_frame('null')).sort_values('null', ascending=False)\n",
    "df_missing_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like MOU for all the types of calls for the month of Jun (6) have missing values together for any particular record.\n",
    "\n",
    "Lets check the records for the MOU for Jun(6), in which these coulmns have missing values together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing the columns of MOU Jun(6)\n",
    "print(((df_missing_columns[df_missing_columns['null'] == 0.44]).index).to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe with the condition, in which MOU for Jun(6) are null\n",
    "df_null_mou_6 = df[(df['loc_og_t2m_mou_6'].isnull()) & (df['loc_ic_t2f_mou_6'].isnull()) & (df['roam_og_mou_6'].isnull()) & (df['std_ic_t2m_mou_6'].isnull()) &\n",
    "  (df['loc_og_t2t_mou_6'].isnull()) & (df['std_ic_t2t_mou_6'].isnull()) & (df['loc_og_t2f_mou_6'].isnull()) & (df['loc_ic_mou_6'].isnull()) &\n",
    "  (df['loc_og_t2c_mou_6'].isnull()) & (df['loc_og_mou_6'].isnull()) & (df['std_og_t2t_mou_6'].isnull()) & (df['roam_ic_mou_6'].isnull()) &\n",
    "  (df['loc_ic_t2m_mou_6'].isnull()) & (df['std_og_t2m_mou_6'].isnull()) & (df['loc_ic_t2t_mou_6'].isnull()) & (df['std_og_t2f_mou_6'].isnull()) & \n",
    "  (df['std_og_t2c_mou_6'].isnull()) & (df['og_others_6'].isnull()) & (df['std_og_mou_6'].isnull()) & (df['spl_og_mou_6'].isnull()) & \n",
    "  (df['std_ic_t2f_mou_6'].isnull()) & (df['isd_og_mou_6'].isnull()) & (df['std_ic_mou_6'].isnull()) & (df['offnet_mou_6'].isnull()) & \n",
    "  (df['isd_ic_mou_6'].isnull()) & (df['ic_others_6'].isnull()) & (df['std_ic_t2o_mou_6'].isnull()) & (df['onnet_mou_6'].isnull()) & \n",
    "  (df['spl_ic_mou_6'].isnull())]\n",
    "\n",
    "df_null_mou_6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the records for which MOU for Jun(6) are null\n",
    "df = df.drop(df_null_mou_6.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Again cheking percent of missing values in columns\n",
    "df_missing_columns = (round(((df.isnull().sum()/len(df.index))*100),2).to_frame('null')).sort_values('null', ascending=False)\n",
    "df_missing_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like MOU for all the types of calls for the month of July (7) have missing values together for any particular record.\n",
    "\n",
    "Lets check the records for the MOU for Jul(7), in which these coulmns have missing values together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing the columns of MOU Jul(7)\n",
    "print(((df_missing_columns[df_missing_columns['null'] == 0.12]).index).to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe with the condition, in which MOU for Jul(7) are null\n",
    "df_null_mou_7 = df[(df['loc_og_t2m_mou_7'].isnull()) & (df['loc_ic_t2f_mou_7'].isnull()) & (df['roam_og_mou_7'].isnull()) & (df['std_ic_t2m_mou_7'].isnull()) &\n",
    "  (df['loc_og_t2t_mou_7'].isnull()) & (df['std_ic_t2t_mou_7'].isnull()) & (df['loc_og_t2f_mou_7'].isnull()) & (df['loc_ic_mou_7'].isnull()) &\n",
    "  (df['loc_og_t2c_mou_7'].isnull()) & (df['loc_og_mou_7'].isnull()) & (df['std_og_t2t_mou_7'].isnull()) & (df['roam_ic_mou_7'].isnull()) &\n",
    "  (df['loc_ic_t2m_mou_7'].isnull()) & (df['std_og_t2m_mou_7'].isnull()) & (df['loc_ic_t2t_mou_7'].isnull()) & (df['std_og_t2f_mou_7'].isnull()) & \n",
    "  (df['std_og_t2c_mou_7'].isnull()) & (df['og_others_7'].isnull()) & (df['std_og_mou_7'].isnull()) & (df['spl_og_mou_7'].isnull()) & \n",
    "  (df['std_ic_t2f_mou_7'].isnull()) & (df['isd_og_mou_7'].isnull()) & (df['std_ic_mou_7'].isnull()) & (df['offnet_mou_7'].isnull()) & \n",
    "  (df['isd_ic_mou_7'].isnull()) & (df['ic_others_7'].isnull()) & (df['std_ic_t2o_mou_7'].isnull()) & (df['onnet_mou_7'].isnull()) & \n",
    "  (df['spl_ic_mou_7'].isnull())]\n",
    "\n",
    "df_null_mou_7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the records for which MOU for Jul(7) are null\n",
    "df = df.drop(df_null_mou_7.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Again cheking percent of missing values in columns\n",
    "df_missing_columns = (round(((df.isnull().sum()/len(df.index))*100),2).to_frame('null')).sort_values('null', ascending=False)\n",
    "df_missing_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there are no more missing values in any columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking percentage of rows we have lost while handling the missing values\n",
    "round((1- (len(df.index)/30011)),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have lost almost 7% records. But we have enough number of records to do our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag churners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now tag the churned customers (churn=1, else 0) based on the fourth month as follows: Those who have not made any calls (either incoming or outgoing) AND have not used mobile internet even once in the churn phase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['churn'] = np.where((df['total_ic_mou_9']==0) & (df['total_og_mou_9']==0) & (df['vol_2g_mb_9']==0) & (df['vol_3g_mb_9']==0), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deleting all the attributes corresponding to the churn phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the columns for churn month(9)\n",
    "col_9 = [col for col in df.columns.to_list() if '_9' in col]\n",
    "print(col_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the churn month columns\n",
    "df = df.drop(col_9, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping sep_vbc_3g column\n",
    "df = df.drop('sep_vbc_3g', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking churn percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(100*(df['churn'].mean()),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is very little percentage of churn rate. We will take care of the class imbalance later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the filtered dataset except mobile_number and churn columns all the columns are numeric types. Hence, converting mobile_number and churn datatype to object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mobile_number'] = df['mobile_number'].astype(object)\n",
    "df['churn'] = df['churn'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List only the numeric columns\n",
    "numeric_cols = df.select_dtypes(exclude=['object']).columns\n",
    "print(numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing outliers below 10th and above 90th percentile\n",
    "for col in numeric_cols: \n",
    "    q1 = df[col].quantile(0.10)\n",
    "    q3 = df[col].quantile(0.90)\n",
    "    iqr = q3-q1\n",
    "    range_low  = q1-1.5*iqr\n",
    "    range_high = q3+1.5*iqr\n",
    "    # Assigning the filtered dataset into data\n",
    "    data = df.loc[(df[col] > range_low) & (df[col] < range_high)]\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derive new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the columns of total mou, rech_num and rech_amt\n",
    "[total for total in data.columns.to_list() if 'total' in total]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deriving new column `decrease_mou_action`\n",
    "This column indicates whether the minutes of usage of the customer has decreased in the action phase than the good phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total mou at good phase incoming and outgoing\n",
    "data['total_mou_good'] = (data['total_og_mou_6'] + data['total_ic_mou_6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg. mou at action phase\n",
    "# We are taking average because there are two months(7 and 8) in action phase\n",
    "data['avg_mou_action'] = (data['total_og_mou_7'] + data['total_og_mou_8'] + data['total_ic_mou_7'] + data['total_ic_mou_8'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference avg_mou_good and avg_mou_action\n",
    "data['diff_mou'] = data['avg_mou_action'] - data['total_mou_good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking whether the mou has decreased in action phase\n",
    "data['decrease_mou_action'] = np.where((data['diff_mou'] < 0), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deriving new column `decrease_rech_num_action`\n",
    "This column indicates whether the number of recharge of the customer has decreased in the action phase than the good phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg rech number at action phase\n",
    "data['avg_rech_num_action'] = (data['total_rech_num_7'] + data['total_rech_num_8'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference total_rech_num_6 and avg_rech_action\n",
    "data['diff_rech_num'] = data['avg_rech_num_action'] - data['total_rech_num_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if rech_num has decreased in action phase\n",
    "data['decrease_rech_num_action'] = np.where((data['diff_rech_num'] < 0), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deriving new column `decrease_rech_amt_action`\n",
    "This column indicates whether the amount of recharge of the customer has decreased in the action phase than the good phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg rech_amt in action phase\n",
    "data['avg_rech_amt_action'] = (data['total_rech_amt_7'] + data['total_rech_amt_8'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference of action phase rech amt and good phase rech amt\n",
    "data['diff_rech_amt'] = data['avg_rech_amt_action'] - data['total_rech_amt_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if rech_amt has decreased in action phase\n",
    "data['decrease_rech_amt_action'] = np.where((data['diff_rech_amt'] < 0), 1, 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deriving new column `decrease_arpu_action`\n",
    "This column indicates whether the average revenue per customer has decreased in the action phase than the good phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARUP in action phase\n",
    "data['avg_arpu_action'] = (data['arpu_7'] + data['arpu_8'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference of good and action phase ARPU\n",
    "data['diff_arpu'] = data['avg_arpu_action'] - data['arpu_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking whether the arpu has decreased on the action month\n",
    "data['decrease_arpu_action'] = np.where(data['diff_arpu'] < 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deriving new column `decrease_vbc_action`\n",
    "This column indicates whether the volume based cost of the customer has decreased in the action phase than the good phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VBC in action phase\n",
    "data['avg_vbc_3g_action'] = (data['jul_vbc_3g'] + data['aug_vbc_3g'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference of good and action phase VBC\n",
    "data['diff_vbc'] = data['avg_vbc_3g_action'] - data['jun_vbc_3g']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking whether the VBC has decreased on the action month\n",
    "data['decrease_vbc_action'] = np.where(data['diff_vbc'] < 0 , 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Churn rate on the basis whether the customer decreased her/his MOU in action month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting churn column to int in order to do aggfunc in the pivot table\n",
    "data['churn'] = data['churn'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.pivot_table(values='churn', index='decrease_mou_action', aggfunc='mean').plot.bar()\n",
    "plt.ylabel('churn rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Analysis***\n",
    "\n",
    "We can see that the churn rate is more for the customers, whose minutes of usage(mou) decreased in the action phase than the good phase. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Churn rate on the basis whether the customer decreased her/his number of recharge in action month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.pivot_table(values='churn', index='decrease_rech_num_action', aggfunc='mean').plot.bar()\n",
    "plt.ylabel('churn rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Analysis***\n",
    "\n",
    "As expected, the churn rate is more for the customers, whose number of recharge in the action phase is lesser than the number in good phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Churn rate on the basis whether the customer decreased her/his amount of recharge in action month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.pivot_table(values='churn', index='decrease_rech_amt_action', aggfunc='mean').plot.bar()\n",
    "plt.ylabel('churn rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Analysis***\n",
    "\n",
    "Here also we see the same behaviour. The churn rate is more for the customers, whose amount of recharge in the action phase is lesser than the amount in good phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Churn rate on the basis whether the customer decreased her/his volume based cost in action month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.pivot_table(values='churn', index='decrease_vbc_action', aggfunc='mean').plot.bar()\n",
    "plt.ylabel('churn rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Analysis***\n",
    "\n",
    "Here we see the expected result. The churn rate is more for the customers, whose volume based cost in action month is increased. That means the customers do not do the monthly recharge more when they are in the action phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis of the average revenue per customer (churn and not churn) in the action phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating churn dataframe\n",
    "data_churn = data[data['churn'] == 1]\n",
    "# Creating not churn dataframe\n",
    "data_non_churn = data[data['churn'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Distribution plot\n",
    "ax = sns.distplot(data_churn['avg_arpu_action'],label='churn',hist=False)\n",
    "ax = sns.distplot(data_non_churn['avg_arpu_action'],label='not churn',hist=False)\n",
    "ax.set(xlabel='Action phase ARPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average revenue per user (ARPU) for the churned customers is mostly densed on the 0 to 900. The higher ARPU customers are less likely to be churned.\n",
    "\n",
    "ARPU for the not churned customers is mostly densed on the 0 to 1000. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis of the minutes of usage MOU (churn and not churn) in the action phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Distribution plot\n",
    "ax = sns.distplot(data_churn['total_mou_good'],label='churn',hist=False)\n",
    "ax = sns.distplot(data_non_churn['total_mou_good'],label='non churn',hist=False)\n",
    "ax.set(xlabel='Action phase MOU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minutes of usage(MOU) of the churn customers is mostly populated on the 0 to 2500 range. Higher the MOU, lesser the churn probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis of churn rate by the decreasing recharge amount and number of recharge in the action phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.pivot_table(values='churn', index='decrease_rech_amt_action', columns='decrease_rech_num_action', aggfunc='mean').plot.bar()\n",
    "plt.ylabel('churn rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Analysis***\n",
    "\n",
    "We can see from the above plot, that the churn rate is more for the customers, whose recharge amount as well as number of recharge have decreased in the action phase than the good phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis of churn rate by the decreasing recharge amount and volume based cost in the action phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.pivot_table(values='churn', index='decrease_rech_amt_action', columns='decrease_vbc_action', aggfunc='mean').plot.bar()\n",
    "plt.ylabel('churn rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Analysis***\n",
    "\n",
    "Here, also we can see that the churn rate is more for the customers, whose recharge amount is decreased along with the volume based cost is increased in the action month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis of recharge amount and number of recharge in action month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "ax = sns.scatterplot('avg_rech_num_action','avg_rech_amt_action', hue='churn', data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Analysis***\n",
    "\n",
    "We can see from the above pattern that the recharge number and the recharge amount are mostly propotional. More the number of recharge, more the amount of the recharge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping few derived columns, which are not required in further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['total_mou_good','avg_mou_action','diff_mou','avg_rech_num_action','diff_rech_num','avg_rech_amt_action',\n",
    "                 'diff_rech_amt','avg_arpu_action','diff_arpu','avg_vbc_3g_action','diff_vbc','avg_rech_amt_6_7'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting feature variables into X\n",
    "X = data.drop(['mobile_number','churn'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting target variable to y\n",
    "y = data['churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train and test set 80:20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with data imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are creating synthetic samples by doing upsampling using SMOTE(Synthetic Minority Oversampling Technique)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imporing SMOTE\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate SMOTE\n",
    "sm = SMOTE(random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fittign SMOTE to the train set\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization method\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Scaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of the numeric columns\n",
    "cols_scale = X_train.columns.to_list()\n",
    "# Removing the derived binary columns \n",
    "cols_scale.remove('decrease_mou_action')\n",
    "cols_scale.remove('decrease_rech_num_action')\n",
    "cols_scale.remove('decrease_rech_amt_action')\n",
    "cols_scale.remove('decrease_arpu_action')\n",
    "cols_scale.remove('decrease_vbc_action')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the data into scaler and transform\n",
    "X_train[cols_scale] = scaler.fit_transform(X_train[cols_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scaling the test set\n",
    "We don't fit scaler on the test set. We only transform the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the test set\n",
    "X_test[cols_scale] = scaler.transform(X_test[cols_scale])\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import PCA\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate PCA\n",
    "pca = PCA(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit train set on PCA\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principal components\n",
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumuliative varinace of the PCs\n",
    "variance_cumu = np.cumsum(pca.explained_variance_ratio_)\n",
    "print(variance_cumu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting scree plot\n",
    "fig = plt.figure(figsize = (10,6))\n",
    "plt.plot(variance_cumu)\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Variance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that `60 components` explain amost more than 90% variance of the data. So, we will perform PCA with 60 components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Performing PCA with 60 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing incremental PCA\n",
    "from sklearn.decomposition import IncrementalPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate PCA with 60 components\n",
    "pca_final = IncrementalPCA(n_components=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the X_train\n",
    "X_train_pca = pca_final.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying transformation on the test set\n",
    "We are only doing Transform in the test set not the Fit-Transform. Because the Fitting is already done on the train set. So, we just have to do the transformation with the already fitted data on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pca = pca_final.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Emphasize Sensitivity/Recall than Accuracy\n",
    "\n",
    "We are more focused on higher Sensitivity/Recall score than the accuracy.\n",
    "\n",
    "Beacuse we need to care more about churn cases than the not churn cases. The main goal is to reatin the customers, who have the possiblity to churn. There should not be a problem, if we consider few not churn customers as churn customers and provide them some incentives for retaining them. Hence, the sensitivity score is more important here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing scikit logistic regression module\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impoting metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning hyperparameter  C\n",
    "C is the the inverse of regularization strength in Logistic Regression. Higher values of C correspond to less regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries for cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating KFold object with 5 splits\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=4)\n",
    "\n",
    "# Specify params\n",
    "params = {\"C\": [0.01, 0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "# Specifing score as recall as we are more focused on acheiving the higher sensitivity than the accuracy\n",
    "model_cv = GridSearchCV(estimator = LogisticRegression(),\n",
    "                        param_grid = params, \n",
    "                        scoring= 'recall', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True) \n",
    "\n",
    "# Fit the model\n",
    "model_cv.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results of grid search CV\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of C versus train and validation scores\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(cv_results['param_C'], cv_results['mean_test_score'])\n",
    "plt.plot(cv_results['param_C'], cv_results['mean_train_score'])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('sensitivity')\n",
    "plt.legend(['test result', 'train result'], loc='upper left')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best score with best C\n",
    "best_score = model_cv.best_score_\n",
    "best_C = model_cv.best_params_['C']\n",
    "\n",
    "print(\" The highest test sensitivity is {0} at C = {1}\".format(best_score, best_C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression with optimal C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with best C\n",
    "logistic_pca = LogisticRegression(C=best_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on the train set\n",
    "log_pca_model = logistic_pca.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the train set\n",
    "y_train_pred = log_pca_model.predict(X_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "confusion = metrics.confusion_matrix(y_train, y_train_pred)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "print(\"Accuracy:-\",metrics.accuracy_score(y_train, y_train_pred))\n",
    "\n",
    "# Sensitivity\n",
    "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
    "\n",
    "# Specificity\n",
    "print(\"Specificity:-\", TN / float(TN+FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on the test set\n",
    "y_test_pred = log_pca_model.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "confusion = metrics.confusion_matrix(y_test, y_test_pred)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "print(\"Accuracy:-\",metrics.accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "# Sensitivity\n",
    "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
    "\n",
    "# Specificity\n",
    "print(\"Specificity:-\", TN / float(TN+FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Model summary***\n",
    "\n",
    "- Train set\n",
    "    - Accuracy = 0.86\n",
    "    - Sensitivity = 0.89\n",
    "    - Specificity = 0.83\n",
    "- Test set\n",
    "    - Accuracy = 0.83\n",
    "    - Sensitivity = 0.81\n",
    "    - Specificity = 0.83\n",
    "    \n",
    "Overall, the model is performing well in the test set, what it had learnt from the train set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine(SVM) with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing SVC\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning\n",
    "\n",
    "C:- Regularization parameter.\n",
    "\n",
    "gamma:- Handles non linear classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify range of hyperparameters\n",
    "\n",
    "hyper_params = [ {'gamma': [1e-2, 1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "\n",
    "# specify model with RBF kernel\n",
    "model = SVC(kernel=\"rbf\")\n",
    "\n",
    "# set up GridSearchCV()\n",
    "model_cv = GridSearchCV(estimator = model, \n",
    "                        param_grid = hyper_params, \n",
    "                        scoring= 'accuracy', \n",
    "                        cv = 3, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv.fit(X_train_pca, y_train)                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv results\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plotting the accuracy with various C and gamma values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting C to numeric type for plotting on x-axis\n",
    "cv_results['param_C'] = cv_results['param_C'].astype('int')\n",
    "\n",
    "# # plotting\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "# subplot 1/3\n",
    "plt.subplot(131)\n",
    "gamma_01 = cv_results[cv_results['param_gamma']==0.01]\n",
    "\n",
    "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_test_score\"])\n",
    "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.01\")\n",
    "plt.ylim([0.80, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "plt.xscale('log')\n",
    "\n",
    "# subplot 2/3\n",
    "plt.subplot(132)\n",
    "gamma_001 = cv_results[cv_results['param_gamma']==0.001]\n",
    "\n",
    "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_test_score\"])\n",
    "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.001\")\n",
    "plt.ylim([0.80, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "plt.xscale('log')\n",
    "\n",
    "\n",
    "# subplot 3/3\n",
    "plt.subplot(133)\n",
    "gamma_0001 = cv_results[cv_results['param_gamma']==0.0001]\n",
    "\n",
    "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_test_score\"])\n",
    "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.0001\")\n",
    "plt.ylim([0.80, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "plt.xscale('log')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the best score \n",
    "best_score = model_cv.best_score_\n",
    "best_hyperparams = model_cv.best_params_\n",
    "\n",
    "print(\"The best test score is {0} corresponding to hyperparameters {1}\".format(best_score, best_hyperparams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plot, we can see that higher value of gamma leads to overfitting the model. With the lowest value of gamma (0.0001) we have train and test accuracy almost same.\n",
    "\n",
    "Also, at C=100 we have a good accuracy and the train and test scores are comparable.\n",
    "\n",
    "Though sklearn suggests the optimal scores mentioned above (gamma=0.01, C=1000), one could argue that it is better to choose a simpler, more non-linear model with gamma=0.0001. This is because the optimal values mentioned here are calculated based on the average test accuracy (but not considering subjective parameters such as model complexity).\n",
    "\n",
    "We can achieve comparable average test accuracy (~90%) with gamma=0.0001 as well, though we'll have to increase the cost C for that. So to achieve high accuracy, there's a tradeoff between:\n",
    "- High gamma (i.e. high non-linearity) and average value of C\n",
    "- Low gamma (i.e. less non-linearity) and high value of C\n",
    "\n",
    "We argue that the model will be simpler if it has as less non-linearity as possible, so we choose gamma=0.0001 and a high C=100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build the model with optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model with optimal hyperparameters\n",
    "svm_pca_model = SVC(C=100, gamma=0.0001, kernel=\"rbf\")\n",
    "\n",
    "svm_pca_model.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the train set\n",
    "y_train_pred = svm_pca_model.predict(X_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "confusion = metrics.confusion_matrix(y_train, y_train_pred)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "print(\"Accuracy:-\",metrics.accuracy_score(y_train, y_train_pred))\n",
    "\n",
    "# Sensitivity\n",
    "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
    "\n",
    "# Specificity\n",
    "print(\"Specificity:-\", TN / float(TN+FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on the test set\n",
    "y_test_pred = svm_pca_model.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "confusion = metrics.confusion_matrix(y_test, y_test_pred)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "print(\"Accuracy:-\",metrics.accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "# Sensitivity\n",
    "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
    "\n",
    "# Specificity\n",
    "print(\"Specificity:-\", TN / float(TN+FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Model summary***\n",
    "\n",
    "- Train set\n",
    "    - Accuracy = 0.89\n",
    "    - Sensitivity = 0.92\n",
    "    - Specificity = 0.85\n",
    "- Test set\n",
    "    - Accuracy = 0.85\n",
    "    - Sensitivity = 0.81\n",
    "    - Specificity = 0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing decision tree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid \n",
    "param_grid = {\n",
    "    'max_depth': range(5, 15, 5),\n",
    "    'min_samples_leaf': range(50, 150, 50),\n",
    "    'min_samples_split': range(50, 150, 50),\n",
    "}\n",
    "\n",
    "\n",
    "# Instantiate the grid search model\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(estimator = dtree, \n",
    "                           param_grid = param_grid, \n",
    "                           scoring= 'recall',\n",
    "                           cv = 5, \n",
    "                           verbose = 1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_pca,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv results\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the optimal sensitivity score and hyperparameters\n",
    "print(\"Best sensitivity:-\", grid_search.best_score_)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model with optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with optimal hyperparameters\n",
    "dt_pca_model = DecisionTreeClassifier(criterion = \"gini\", \n",
    "                                  random_state = 100,\n",
    "                                  max_depth=10, \n",
    "                                  min_samples_leaf=50,\n",
    "                                  min_samples_split=50)\n",
    "\n",
    "dt_pca_model.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the train set\n",
    "y_train_pred = dt_pca_model.predict(X_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "confusion = metrics.confusion_matrix(y_train, y_train_pred)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "print(\"Accuracy:-\",metrics.accuracy_score(y_train, y_train_pred))\n",
    "\n",
    "# Sensitivity\n",
    "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
    "\n",
    "# Specificity\n",
    "print(\"Specificity:-\", TN / float(TN+FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on the test set\n",
    "y_test_pred = dt_pca_model.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "confusion = metrics.confusion_matrix(y_test, y_test_pred)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "print(\"Accuracy:-\",metrics.accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "# Sensitivity\n",
    "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
    "\n",
    "# Specificity\n",
    "print(\"Specificity:-\", TN / float(TN+FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Model summary***\n",
    "\n",
    "- Train set\n",
    "    - Accuracy = 0.90\n",
    "    - Sensitivity = 0.91\n",
    "    - Specificity = 0.88\n",
    "- Test set\n",
    "    - Accuracy = 0.86\n",
    "    - Sensitivity = 0.70\n",
    "    - Specificity = 0.87\n",
    "    \n",
    "    \n",
    "We can see from the model performance that the Sesitivity has been decreased while evaluating the model on the test set. However, the accuracy and specificity is quite good in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': range(5,10,5),\n",
    "    'min_samples_leaf': range(50, 150, 50),\n",
    "    'min_samples_split': range(50, 150, 50),\n",
    "    'n_estimators': [100,200,300], \n",
    "    'max_features': [10, 20]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, \n",
    "                           param_grid = param_grid, \n",
    "                           cv = 3,\n",
    "                           n_jobs = -1,\n",
    "                           verbose = 1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train_pca, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the optimal accuracy score and hyperparameters\n",
    "print('We can get accuracy of',grid_search.best_score_,'using',grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model with optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with the best hyperparameters\n",
    "\n",
    "rfc_model = RandomForestClassifier(bootstrap=True,\n",
    "                             max_depth=5,\n",
    "                             min_samples_leaf=50, \n",
    "                             min_samples_split=100,\n",
    "                             max_features=20,\n",
    "                             n_estimators=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "rfc_model.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the train set\n",
    "y_train_pred = rfc_model.predict(X_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "confusion = metrics.confusion_matrix(y_train, y_train_pred)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "print(\"Accuracy:-\",metrics.accuracy_score(y_train, y_train_pred))\n",
    "\n",
    "# Sensitivity\n",
    "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
    "\n",
    "# Specificity\n",
    "print(\"Specificity:-\", TN / float(TN+FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on the test set\n",
    "y_test_pred = rfc_model.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "confusion = metrics.confusion_matrix(y_test, y_test_pred)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "print(\"Accuracy:-\",metrics.accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "# Sensitivity\n",
    "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
    "\n",
    "# Specificity\n",
    "print(\"Specificity:-\", TN / float(TN+FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Model summary***\n",
    "\n",
    "- Train set\n",
    "    - Accuracy = 0.84\n",
    "    - Sensitivity = 0.88\n",
    "    - Specificity = 0.80\n",
    "- Test set\n",
    "    - Accuracy = 0.80\n",
    "    - Sensitivity = 0.75\n",
    "    - Specificity = 0.80\n",
    "    \n",
    "    \n",
    "We can see from the model performance that the Sesitivity has been decreased while evaluating the model on the test set. However, the accuracy and specificity is quite good in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final conclusion with PCA\n",
    "After trying several models we can see that for acheiving the best sensitivity, which was our ultimate goal, the classic Logistic regression or the SVM models preforms well. For both the models the sensitivity was approx 81%. Also we have good accuracy of apporx 85%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression with No PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Importing stats model\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "# Adding the constant to X_train\n",
    "log_no_pca = sm.GLM(y_train,(sm.add_constant(X_train)), family=sm.families.Binomial())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "log_no_pca = log_no_pca.fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "log_no_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Model analysis***\n",
    "1. We can see that there are few features have positive coefficients and few have negative.\n",
    "2. Many features have higher p-values and hence became insignificant in the model.\n",
    "\n",
    "***Coarse tuning (Auto+Manual)***\n",
    "\n",
    "We'll first eliminate a few features using Recursive Feature Elimination (RFE), and once we have reached a small set of variables to work with, we can then use manual feature elimination (i.e. manually eliminating features based on observing the p-values and VIFs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection Using RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing logistic regression from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Intantiate the logistic regression\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFE with 15 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing RFE\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Intantiate RFE with 15 columns\n",
    "rfe = RFE(logreg, 15)\n",
    "\n",
    "# Fit the rfe model with train set\n",
    "rfe = rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE selected columns\n",
    "rfe_cols = X_train.columns[rfe.support_]\n",
    "print(rfe_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-1 with RFE selected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding constant to X_train\n",
    "X_train_sm_1 = sm.add_constant(X_train[rfe_cols])\n",
    "\n",
    "#Instantiate the model\n",
    "log_no_pca_1 = sm.GLM(y_train, X_train_sm_1, family=sm.families.Binomial())\n",
    "\n",
    "# Fit the model\n",
    "log_no_pca_1 = log_no_pca_1.fit()\n",
    "\n",
    "log_no_pca_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking VIFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the VIF values of the feature variables. \n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[rfe_cols].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[rfe_cols].values, i) for i in range(X_train[rfe_cols].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removing column og_others_8, which is insignificatnt as it has the highest p-value 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing og_others_8 column \n",
    "log_cols = rfe_cols.to_list()\n",
    "log_cols.remove('og_others_8')\n",
    "print(log_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-2\n",
    "Building the model after removing og_others_8 variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding constant to X_train\n",
    "X_train_sm_2 = sm.add_constant(X_train[log_cols])\n",
    "\n",
    "#Instantiate the model\n",
    "log_no_pca_2 = sm.GLM(y_train, X_train_sm_2, family=sm.families.Binomial())\n",
    "\n",
    "# Fit the model\n",
    "log_no_pca_2 = log_no_pca_2.fit()\n",
    "\n",
    "log_no_pca_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking VIF for Model-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[log_cols].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[log_cols].values, i) for i in range(X_train[log_cols].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the model summary that all the variables p-values are significant and offnet_mou_8 column has the highest VIF 7.45. Hence, deleting offnet_mou_8 column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing offnet_mou_8 column\n",
    "log_cols.remove('offnet_mou_8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-3\n",
    "Model after removing offnet_mou_8 column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding constant to X_train\n",
    "X_train_sm_3 = sm.add_constant(X_train[log_cols])\n",
    "\n",
    "#Instantiate the model\n",
    "log_no_pca_3 = sm.GLM(y_train, X_train_sm_3, family=sm.families.Binomial())\n",
    "\n",
    "# Fit the model\n",
    "log_no_pca_3 = log_no_pca_3.fit()\n",
    "\n",
    "log_no_pca_3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VIF Model-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[log_cols].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[log_cols].values, i) for i in range(X_train[log_cols].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now from the model summary and the VIF list we can see that all the variables are significant and there is no multicollinearity among the variables.\n",
    "\n",
    "Hence, we can conclused that ***Model-3 log_no_pca_3 will be the final model***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model performance on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the predicted value on the train set\n",
    "y_train_pred_no_pca = log_no_pca_3.predict(X_train_sm_3)\n",
    "y_train_pred_no_pca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a dataframe with the actual churn and the predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final = pd.DataFrame({'churn':y_train.values, 'churn_prob':y_train_pred_no_pca.values})\n",
    "\n",
    "#Assigning Customer ID for each record for better readblity\n",
    "#CustID is the index of each record.\n",
    "y_train_pred_final['CustID'] = y_train_pred_final.index\n",
    "\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finding Optimal Probablity Cutoff Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating columns for different probablity cutoffs\n",
    "prob_cutoff = [float(p/10) for p in range(10)]\n",
    "\n",
    "for i in prob_cutoff:\n",
    "    y_train_pred_final[i] = y_train_pred_final['churn_prob'].map(lambda x : 1 if x > i else 0)\n",
    "    \n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now let's calculate the accuracy sensitivity and specificity for various probability cutoffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe\n",
    "cutoff_df = pd.DataFrame(columns=['probability', 'accuracy', 'sensitivity', 'specificity'])\n",
    "\n",
    "for i in prob_cutoff:\n",
    "    cm1 = metrics.confusion_matrix(y_train_pred_final['churn'], y_train_pred_final[i] )\n",
    "    total1=sum(sum(cm1))\n",
    "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "    \n",
    "    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
    "print(cutoff_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting accuracy, sensitivity and specificity for different probabilities.\n",
    "cutoff_df.plot('probability', ['accuracy','sensitivity','specificity'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis of the above curve\n",
    "Accuracy - Becomes stable around 0.6\n",
    "\n",
    "Sensitivity - Decreases with the increased probablity.\n",
    "\n",
    "Specificity - Increases with the increasing probablity.\n",
    "\n",
    "`At point 0.6` where the three parameters cut each other, we can see that there is a balance bethween sensitivity and specificity with a good accuracy.\n",
    "\n",
    "Here we are intended to acheive better sensitivity than accuracy and specificity. Though as per the above curve, we should take 0.6 as the optimum probability cutoff, we are taking ***0.5*** for acheiving higher sensitivity, which is our main goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a column with name \"predicted\", which is the predicted value for 0.5 cutoff \n",
    "y_train_pred_final['predicted'] = y_train_pred_final['churn_prob'].map(lambda x: 1 if x > 0.5 else 0)\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion metrics\n",
    "confusion = metrics.confusion_matrix(y_train_pred_final['churn'], y_train_pred_final['predicted'])\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "print(\"Accuracy:-\",metrics.accuracy_score(y_train_pred_final['churn'], y_train_pred_final['predicted']))\n",
    "\n",
    "# Sensitivity\n",
    "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
    "\n",
    "# Specificity\n",
    "print(\"Specificity:-\", TN / float(TN+FP))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have got good accuracy, sensitivity and specificity on the train set prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plotting the ROC Curve (Trade off between sensitivity & specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve function\n",
    "\n",
    "def draw_roc( actual, probs ):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n",
    "                                              drop_intermediate = False )\n",
    "    auc_score = metrics.roc_auc_score( actual, probs )\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_roc(y_train_pred_final['churn'], y_train_pred_final['churn_prob'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the area of the ROC curve is closer to 1, whic is the Gini of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking a copy of the test set\n",
    "X_test_log = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking only the columns, which are selected in the train set after removing insignificant and multicollinear variables\n",
    "X_test_log = X_test_log[log_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding constant on the test set\n",
    "X_test_sm = sm.add_constant(X_test_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions on the test set with final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_test_pred = log_no_pca_3.predict(X_test_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting y_test_pred to a dataframe because y_test_pred is an array\n",
    "y_pred_1 = pd.DataFrame(y_test_pred)\n",
    "y_pred_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convetting y_test to a dataframe\n",
    "y_test_df = pd.DataFrame(y_test)\n",
    "y_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting index to Customer ID \n",
    "y_test_df['CustID'] = y_test_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing index form the both dataframes for merging them side by side\n",
    "y_pred_1.reset_index(drop=True, inplace=True)\n",
    "y_test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending y_pred_1 and y_test_df\n",
    "y_test_pred_final = pd.concat([y_test_df, y_pred_1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the '0' column as churn probablity\n",
    "y_test_pred_final = y_test_pred_final.rename(columns={0:'churn_prob'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearranging the columns\n",
    "y_test_pred_final = y_test_pred_final.reindex_axis(['CustID','churn','churn_prob'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the test set using probablity cutoff 0.5, what we got in the train set \n",
    "y_test_pred_final['test_predicted'] = y_test_pred_final['churn_prob'].map(lambda x: 1 if x > 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test_pred_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_test_pred_final\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test_pred_final' is not defined"
     ]
    }
   ],
   "source": [
    "y_test_pred_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4190 1158]\n",
      " [  34  159]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "confusion = metrics.confusion_matrix(y_test_pred_final['churn'], y_test_pred_final['test_predicted'])\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:- 0.7848763761053962\n",
      "Sensitivity:- 0.8238341968911918\n",
      "Specificity:- 0.7834704562453254\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "print(\"Accuracy:-\",metrics.accuracy_score(y_test_pred_final['churn'], y_test_pred_final['test_predicted']))\n",
    "\n",
    "# Sensitivity\n",
    "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
    "\n",
    "# Specificity\n",
    "print(\"Specificity:-\", TN / float(TN+FP))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Model summary***\n",
    "\n",
    "- Train set\n",
    "    - Accuracy = 0.84\n",
    "    - Sensitivity = 0.81\n",
    "    - Specificity = 0.83\n",
    "- Test set\n",
    "    - Accuracy = 0.78\n",
    "    - Sensitivity = 0.82\n",
    "    - Specificity = 0.78\n",
    "    \n",
    "Overall, the model is performing well in the test set, what it had learnt from the train set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final conclusion with no PCA\n",
    "\n",
    "We can see that the logistic model with no PCA has good sensitivity and accuracy, which are comparable to the models with PCA. So, we can go for the more simplistic model such as logistic regression with PCA as it expliains the important predictor variables as well as the significance of each variable. The model also hels us to identify the variables which should be act upon for making the decision of the to be churned customers. Hence, the model is more relevant in terms of explaining to the business."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business recomendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top predictors\n",
    "\n",
    "Below are few top variables selected in the logistic regression model.\n",
    "\n",
    "| Variables   | Coefficients |\n",
    "|---------------------|--------------|\n",
    "|loc_ic_mou_8|-3.3287|\n",
    "|og_others_7|-2.4711|\n",
    "|ic_others_8|-1.5131|\n",
    "|isd_og_mou_8|-1.3811|\n",
    "|decrease_vbc_action|-1.3293|\n",
    "|monthly_3g_8|-1.0943|\n",
    "|std_ic_t2f_mou_8|-0.9503|\n",
    "|monthly_2g_8|-0.9279|\n",
    "|loc_ic_t2f_mou_8|-0.7102|\n",
    "|roam_og_mou_8|0.7135|\n",
    "\n",
    "We can see most of the top variables have negative coefficients. That means, the variables are inversely correlated with the churn probablity.\n",
    "\n",
    "E.g.:- \n",
    "\n",
    "If the local incoming minutes of usage (loc_ic_mou_8) is lesser in the month of August than any other month, then there is a higher chance that the customer is likely to churn.\n",
    "\n",
    "***Recomendations***\n",
    "\n",
    "1. Target the customers, whose minutes of usage of the incoming local calls and outgoing ISD calls are less in the action phase (mostly in the month of August).\n",
    "2. Target the customers, whose outgoing others charge in July and incoming others on August are less.\n",
    "3. Also, the customers having value based cost in the action phase increased are more likely to churn than the other customers. Hence, these customers may be a good target to provide offer.\n",
    "4. Cutomers, whose monthly 3G recharge in August is more, are likely to be churned. \n",
    "5. Customers having decreasing STD incoming minutes of usage for operators T to fixed lines of T for the month of August are more likely to churn.\n",
    "6. Cutomers decreasing monthly 2g usage for August are most probable to churn.\n",
    "7. Customers having decreasing incoming minutes of usage for operators T to fixed lines of T for August are more likely to churn.\n",
    "8. roam_og_mou_8 variables have positive coefficients (0.7135). That means for the customers, whose roaming outgoing minutes of usage is increasing are more likely to churn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots of important predictors for churn and non churn customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting loc_ic_mou_8 predictor for churn and not churn customers\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "sns.distplot(data_churn['loc_ic_mou_8'],label='churn',hist=False)\n",
    "sns.distplot(data_non_churn['loc_ic_mou_8'],label='not churn',hist=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for the churn customers the minutes of usage for the month of August is mostly populated on the lower side than the non churn customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlkAAAF0CAYAAAAQIiwyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAf+klEQVR4nO3df5RdZX3v8fc3M0kmRAgQsFUSmVCCEkqIECMCFq4oC10WxEaFooCXVZatWLtsVbjeIrDKWrV1XdRia/HHDeZaAUNr0xpLK9QiVIGJiUKMaMQow88QIBIwPybzvX+cPeFkmMmcJOeZMzPn/VrrrLN/PHvv73lmJnzYe5/9RGYiSZKk5prU6gIkSZImIkOWJElSAYYsSZKkAgxZkiRJBRiyJEmSCjBkSZIkFdDZ6gIGO+SQQ7K7u7vVZUiSJI1o5cqVT2bmoUOtG3Mhq7u7m56enlaXIUmSNKKI+MVw67xcKEmSVIAhS5IkqQBDliRJUgFj7p4sSZLUHNu3b6e3t5ctW7a0upRxr6uri1mzZjF58uSGtzFkSZI0QfX29rL//vvT3d1NRLS6nHErM9m4cSO9vb3MmTOn4e28XChJ0gS1ZcsWZs6cacDaRxHBzJkz9/iMoCFLkqQJzIDVHHvTj4YsSZI0qi666CKWLVvW6jKKM2RJkqRxZceOHa0uoSGGLEmSVNSXv/xl5s+fz3HHHcd73vMeAO644w5OOukkjjjiiJ1ntb797W/z1re+ded2l156KUuWLAFqI8JcffXVnHLKKXzta1/jtNNO46Mf/SiLFi3iqKOO4jvf+c6of66R+O1CSZLawFX/soYfPfKrpu5z3ssP4OO/e8xu26xZs4ZrrrmGu+66i0MOOYSnnnqKD33oQzz66KPceeed/PjHP+ass85i8eLFIx6vq6uLO++8E4DPfe5z9PX1cc8997BixQquuuoqvvWtbzXlczWLZ7IkSVIxt99+O4sXL+aQQw4B4OCDDwbgbW97G5MmTWLevHk8/vjjDe3rXe961y7zb3/72wE44YQTWL9+ffOKbpK2PJO1eWsfd/xkA2859mWtLkWSpFEx0hmnUjJzyG/mTZ06dZc2AJ2dnfT39+9cPviRCdOnTx9yHx0dHfT19TWt5mZpyzNZl//jffzRV77P2kebe9pUkiTt6vTTT+fmm29m48aNADz11FPDtj388MP50Y9+xNatW9m0aRO33XbbaJVZRFueyep9+nkAnt82Pr6dIEnSeHXMMcfwsY99jFNPPZWOjg5e/epXD9t29uzZvPOd72T+/PnMnTt3t23Hgxg4RTdWLFy4MHt6eooe45y/vYtVv3yGW/7wJE44/KCix5IkqVXWrl3L0Ucf3eoyJoyh+jMiVmbmwqHat+XlQkmSpNIMWZIkSQUYsiRJkgowZEmSJBVgyJIkSSrAkCVJklSAIUuSJI0ZS5Ys4ZFHHmm4/eBBpccSQ5YkSRoz9jRk7auSw/EYsiRJUhHr16/n6KOP5g/+4A845phjOOOMM/j1r38NwOrVqznxxBOZP38+55xzDk8//TTLli2jp6eH888/nwULFuxsO2DdunW88Y1v5LjjjuP444/nZz/7GQCbN29m8eLFvOpVr+L888/fORZid3c3Tz75JAA9PT2cdtppAFx55ZVccsklnHHGGVxwwQUsWbKEt7/97Zx55pnMnTuXj3zkI035/G05rI4kSW3nm5fBY/c1d5+/eSy8+S932+SnP/0pX/3qV/n85z/PO9/5Tm655Rbe/e53c8EFF/A3f/M3nHrqqVxxxRVcddVVfOpTn+K6667jk5/8JAsXvvgh6ueffz6XXXYZ55xzDlu2bKG/v5+HHnqIVatWsWbNGl7+8pdz8sknc9ddd3HKKafstq6VK1dy5513Mm3aNJYsWcLq1atZtWoVU6dO5ZWvfCUf+MAHmD179j51j2eyJElSMXPmzGHBggUAnHDCCaxfv55NmzbxzDPPcOqppwJw4YUXcscdd+x2P88++ywPP/ww55xzDgBdXV3st99+ACxatIhZs2YxadIkFixYwPr160es66yzzmLatGk7508//XRmzJhBV1cX8+bN4xe/+MXefNxdeCZLkqR2MMIZp1KmTp26c7qjo+NFlwAbtbuxlgcfY+A+q87OTvr7+wHYsmXLLttMnz69oX3sC89kSZKkUTVjxgwOOuggvvOd7wCwdOnSnWe19t9/f5599tkXbXPAAQcwa9Ysvv71rwOwdetWnn/++d0ep7u7m5UrVwJwyy23NPMjNMSQJUmSRt0NN9zAhz/8YebPn8/q1au54oorALjooot43/veN+SN70uXLuUzn/kM8+fP56STTuKxxx7b7TE+/vGP88EPfpDXv/71dHR0FPssw4ndnX5rhYULF2ZPT0/RY5zzt3ex6pfPcMsfnsQJhx9U9FiSJLXK2rVrOfroo1tdxoQxVH9GxMrMfPFd+ngmS5IkqQhDliRJUgGGLEmSpAIMWZIkTWBj7d7r8Wpv+tGQJUnSBNXV1cXGjRsNWvsoM9m4cSNdXV17tJ0PI5UkaYKaNWsWvb29bNiwodWljHtdXV3MmjVrj7YxZEmSNEFNnjyZOXPmtLqMtuXlQkmSpALaMmR5aVqSJJXWliFrQESrK5AkSRNVW4csSZKkUgxZkiRJBRiyJEmSCmjrkOUN8JIkqZS2DFne8C5JkkprKGRFxJkR8UBErIuIy4ZYPzUibqrW3x0R3YPWvyIiNkfEnzWnbEmSpLFtxJAVER3AZ4E3A/OA8yJi3qBmFwNPZ+aRwLXAJwatvxb45r6XK0mSND40ciZrEbAuMx/MzG3AjcDZg9qcDdxQTS8DTo+oXZSLiLcBDwJrmlOyJEnS2NdIyDoMeKhuvrdaNmSbzOwDNgEzI2I68FHgqn0vVZIkafxoJGQNdZv44O/lDdfmKuDazNy82wNEXBIRPRHR40jhkiRpIuhsoE0vMLtufhbwyDBteiOiE5gBPAW8FlgcEX8FHAj0R8SWzLyufuPMvB64HmDhwoU+WEGSJI17jYSse4G5ETEHeBg4F/j9QW2WAxcC3wUWA7dnZgKvH2gQEVcCmwcHLEmSpIloxJCVmX0RcSlwK9ABfCkz10TE1UBPZi4HvggsjYh11M5gnVuyaEmSpLGukTNZZOYKYMWgZVfUTW8B3jHCPq7ci/okSZLGpbZ84rskSVJphixJkqQCDFmSJEkFGLIkSZIKMGRJkiQV0JYh64e9m1pdgiRJmuDaMmTt6Peh8pIkqay2DFmSJEmlGbIkSZIKMGRJkiQVYMiSJEkqoK1DVkSrK5AkSRNVW4csSZKkUgxZkiRJBRiyJEmSCjBkSZIkFWDIkiRJKsCQJUmSVIAhC9jat4M/+spKbl3zWKtLkSRJE4QhC+jvhxX3PcbPn3yu1aVIkqQJoq1DVmarK5AkSRNVW4csSZKkUgxZkiRJBRiyJEmSCjBkSZIkFWDIkiRJKsCQJUmSVIAhS5IkqQBDliRJUgGGLEmSpAIMWZIkSQUYsiRJkgowZEmSJBXQ1iHr0n/4fqtLkCRJE1Rbh6xHN21pdQmSJGmCauuQJUmSVIohS5IkqQBDliRJUgGGLEmSpAIMWZIkSQUYsiRJkgowZEmSJBVgyJIkSSrAkAUk2eoSJEnSBGPIqhOtLkCSJE0YhixJkqQCDFmSJEkFGLIkSZIKMGRJkiQVYMiSJEkqwJAlSZJUgCFLkiSpAEOWJElSAYYsSZKkAgxZkiRJBbR9yDrqY9/kkWe2tLoMSZI0wbR9yNq2o59vrX281WVIkqQJpu1DliRJUgmGLEmSpAIMWZIkSQU0FLIi4syIeCAi1kXEZUOsnxoRN1Xr746I7mr5oohYXb1+EBHnNLd8SZKksWnEkBURHcBngTcD84DzImLeoGYXA09n5pHAtcAnquX3AwszcwFwJvD3EdHZrOIlSZLGqkbOZC0C1mXmg5m5DbgROHtQm7OBG6rpZcDpERGZ+Xxm9lXLu4BsRtGSJEljXSMh6zDgobr53mrZkG2qULUJmAkQEa+NiDXAfcD76kLXThFxSUT0RETPhg0b9vxTSJIkjTGNhKwYYtngM1LDtsnMuzPzGOA1wOUR0fWihpnXZ+bCzFx46KGHNlCSJEnS2NZIyOoFZtfNzwIeGa5Ndc/VDOCp+gaZuRZ4DvjtvS1WkiRpvGgkZN0LzI2IORExBTgXWD6ozXLgwmp6MXB7Zma1TSdARBwOvBJY35TKJUmSxrARv+mXmX0RcSlwK9ABfCkz10TE1UBPZi4HvggsjYh11M5gnVttfgpwWURsB/qBP8rMJ0t8EEmSpLGkoccpZOYKYMWgZVfUTW8B3jHEdkuBpftYY3Hpdx4lSVKT+cT3OjHU7fuSJEl7wZAlSZJUgCFLkiSpAEOWJElSAYYsSZKkAgxZkiRJBRiyJEmSCjBk4aMbJElS8xmy8GGkkiSp+QxZkiRJBRiyJEmSCjBkSZIkFWDIkiRJKsCQJUmSVIAhS5IkqQBDliRJUgGGLEmSpAIMWZIkSQUYsiRJkgowZEmSJBVgyJIkSSrAkCVJklSAIUuSJKkAQ5YkSVIBhiwgyVaXIEmSJhhDVp0gWl2CJEmaIAxZGK4kSVLzGbIkSZIKMGRJkiQVYMjCG98lSVLzGbIkSZIKMGRJkiQVYMiSJEkqwJAlSZJUgCFLkiSpAEOWJElSAYYsSZKkAgxZkiRJBRiyJEmSCjBkSZIkFWDIkiRJKsCQJUmSVIAhS5IkqQBDliRJUgGGLEmSpAIMWUAQrS5BkiRNMIYsSZKkAgxZkiRJBRiyJEmSCjBkAUm2ugRJkjTBGLKArDJWeP+7JElqEkOWJElSAYYsSZKkAgxZkiRJBRiyJEmSCjBkSZIkFWDIkiRJKsCQJUmSVIAhS5IkqYCGQlZEnBkRD0TEuoi4bIj1UyPipmr93RHRXS1/U0SsjIj7qvc3NLd8SZKksWnEkBURHcBngTcD84DzImLeoGYXA09n5pHAtcAnquVPAr+bmccCFwJLm1W4JEnSWNbImaxFwLrMfDAztwE3AmcPanM2cEM1vQw4PSIiM1dl5iPV8jVAV0RMbUbhkiRJY1kjIesw4KG6+d5q2ZBtMrMP2ATMHNTm94BVmbl170qVJEkaPzobaDPUsMm5J20i4hhqlxDPGPIAEZcAlwC84hWvaKAkSZKksa2RM1m9wOy6+VnAI8O1iYhOYAbwVDU/C/gn4ILM/NlQB8jM6zNzYWYuPPTQQ/fsE0iSJI1BjYSse4G5ETEnIqYA5wLLB7VZTu3GdoDFwO2ZmRFxIPAN4PLMvKtZRTdbDHUeTpIkaR+MGLKqe6wuBW4F1gI3Z+aaiLg6Is6qmn0RmBkR64APAQOPebgUOBL484hYXb1e2vRPIUmSNMY0ck8WmbkCWDFo2RV101uAdwyx3V8Af7GPNUqSJI07PvFdkiSpAEOWJElSAYYsSZKkAgxZkiRJBRiygBz8aFVJkqR9ZMiSJEkqwJAlSZJUgCFLkiSpAEOWJElSAYYsSZKkAgxZkiRJBRiyJEmSCjBkSZIkFWDIkiRJKsCQJUmSVIAhS5IkqQBDliRJUgGGLEmSpAIMWZIkSQUYsiRJkgowZEmSJBVgyJIkSSrAkCVJklSAIUuSJKkAQ5YkSVIBhixJkqQCDFmSJEkFGLIkSZIKMGRJkiQVYMiSJEkqwJAlSZJUgCELyMxWlyBJkiYYQ1adiGh1CZIkaYIwZEmSJBVgyJIkSSrAkCVJklSAIQvvxZIkSc1nyJIkSSrAkCVJklSAIUuSJKkAQ5YkSVIBhixJkqQCDFmSJEkFGLIkSZIKMGRJkiQVYMiSJEkqwJAFZGarS5AkSROMIUuSJKkAQ5YkSVIBbReyvDQoSZJGQ9uFLEmSpNFgyJIkSSrAkCVJklSAIUuSJKmAtgtZ3vcuSZJGQ9uFrKFERKtLkCRJE4whCx/rIEmSms+QVcfzWZIkqVkMWZIkSQW0XcjywqAkSRoNDYWsiDgzIh6IiHURcdkQ66dGxE3V+rsjortaPjMi/jMiNkfEdc0tXZIkaewaMWRFRAfwWeDNwDzgvIiYN6jZxcDTmXkkcC3wiWr5FuDPgT9rWsWSJEnjQCNnshYB6zLzwczcBtwInD2ozdnADdX0MuD0iIjMfC4z76QWtiRJktpGIyHrMOChuvneatmQbTKzD9gEzGy0iIi4JCJ6IqJnw4YNjW4mSZI0ZjUSsoZ6ssHg+8cbaTOszLw+Mxdm5sJDDz200c0kSZLGrEZCVi8wu25+FvDIcG0iohOYATzVjAKbzQePSpKk0dBIyLoXmBsRcyJiCnAusHxQm+XAhdX0YuD2NM1IkqQ21jlSg8zsi4hLgVuBDuBLmbkmIq4GejJzOfBFYGlErKN2Buvcge0jYj1wADAlIt4GnJGZP2r+R9l7xkFJktRsI4YsgMxcAawYtOyKuuktwDuG2bZ7H+qTJEkal9ruie+SJEmjoe1CllcGJUnSaGi7kCVJkjQaDFmSJEkFGLIkSZIKMGQBMdTz6iVJkvZB24Usn4klSZJGQ9uFLEmSpNFgyJIkSSrAkCVJklSAIUuSJKmAtgtZOcQz3zc+tw2Af1r18GiXI0mSJqi2C1lDeXDDcwDc9/CmFlciSZImCkMWjmcoSZKaz5AlSZJUgCELSJ9QKkmSmqztQpZ5SpIkjYa2C1mSJEmjwZAlSZJUgCELLyFKkqTmM2Qx9ANKJUmS9oUhS5IkqQBDliRJUgGGLLwnS5IkNZ8hS5IkqQBDliRJUgFtF7KGujTo5UJJktRsbReyJEmSRoMhS5IkqQBDFj6MVJIkNZ8hC/j+L59pdQmSJGmCMWQB2/r6W12CJEmaYNouZHlpUJIkjYa2C1mSJEmjwZAlSZJUgCFLkiSpAEOWJElSAW0XshxCR5IkjYa2C1mSJEmjwZAlSZJUgCFLkiSpAEOWJElSAW0XsrzvXZIkjYa2C1mSJEmjwZAlSZJUgCFLkiSpAEOWJElSAW0XstJHvkuSpFHQdiFLkiRpNBiyJEmSCjBkSZIkFWDIkiRJKqDtQpa3vUuSpNHQdiFLkiRpNBiyJEmSCjBkSZIkFWDIkiRJKqDtQpYPfJckSaOh7ULWHtu+BTb8BHZsb3UlkiRpHOlspFFEnAl8GugAvpCZfzlo/VTgy8AJwEbgXZm5vlp3OXAxsAP448y8tWnVl7DtObj7c/Dw9+GJtfD0zyH74cBXwMl/Aq9+N3RObXWVkiRpjBsxZEVEB/BZ4E1AL3BvRCzPzB/VNbsYeDozj4yIc4FPAO+KiHnAucAxwMuBb0XEUZm5o9kfpBleEz+Gv/tf8PR6OOQo+I1j4NjFsP9vwqqvwDc+BHf8Nbzu/XDwEdC3pXamq+/X1Xv12rGtFsp+47fhpfOg64BWfzRJkjTKGjmTtQhYl5kPAkTEjcDZQH3IOhu4sppeBlwXEVEtvzEztwI/j4h11f6+25zy90ImM9nEZqaxlclA0MVWPtx5M+/t+DfgcLjoG9B9yq7bnfBe+Pl/wR2fhH//37s5QMCkTuivu7w4YzbsdzBM3g8mT6u9v+SlMGMWHDCrFuK2bYbNT8BzG2qvvq2QO6B/R+1GsgNeBgfNqYW7gw6v7bc+4E3qgI7J0DEFJk2upgfmO2tn47K/2t+OQe+Dl/fXfZyofaYp02HKS2rvk/eDbc/Cr5+uvbb8qnacKdOr9dNql1d3bKt9jv7tEB21Nh2Ta/UMTHdMfqHeSZ3V8Zrzc6a/r1ZDfx9Mng4dQ/y6D7QbfOxM2LIJnt8IW38F0w6C6S+FKfvt2mbb5trZz4G+aVb9kqRxr5GQdRjwUN18L/Da4dpkZl9EbAJmVsu/N2jbw/a62mbYtpmVXX9Ym8wONjONDvqZEc9zQ9+buPB9S2DqS168XQQccVrtteEnsP35WpjonAqd02ByF3R21cIDwKZeeHwNPH4/bPgxbH22ts3WZ+HZx+AXd9UCylC6Dqzta1JH7ZXAs4/uGtwmqvqAOKk+JO6ohaH+PtjR98J0f19tHUBMqr2Iofuqswum7l/7ufVthW3Pw/bnXgiVnV21n+ekzlrA6u978T4mT68Fru3P1cJl/UnZ6ICuGbVjQC2EDYTbIV/VerKqPV74DPUvotZmqO2yv/b7MbCOrK3vmAKdU6Bjau13aMd22LEV+rZVoXdg/x0vHHdSx6DldTXVH2vgGPXH27k+634Wgz/PwL6ohfn+vlpduaPW55PqgvaObdWZ4a21NgM/m86u2u/GLscdND3c+4vqrT4LDN/3u/T/4M853PF48T4m1fUnMQ7D+HirV6p0nwxnf7Zlh28kZA311zX4O3rDtWlkWyLiEuCSanZzRDzQQF376hDgSagPOrdw0TW3jMKhR/KrVhcwlKq/xrNfAU+MsL6RfTy6m/U7f58mQH+NOvtsz9hfe84+2zMToL9+APxt6YMcPtyKRkJWLzC7bn4W8MgwbXojohOYATzV4LZk5vXA9Q3U0jQR0ZOZC0fzmOOZ/bVn7K89Z5/tGftrz9lne8b+2neNPMLhXmBuRMyJiCnUbmRfPqjNcuDCanoxcHtmZrX83IiYGhFzgLnAPc0pXZIkaewa8UxWdY/VpcCt1B7h8KXMXBMRVwM9mbkc+CKwtLqx/SlqQYyq3c3UbpLvA94/Vr9ZKEmS1EwNPScrM1cAKwYtu6JuegvwjmG2vQa4Zh9qLGVUL09OAPbXnrG/9px9tmfsrz1nn+0Z+2sfRTrOjCRJUtM5rI4kSVIBbReyIuLMiHggItZFxGWtrmesiIgvRcQTEXF/3bKDI+I/IuKn1ftB1fKIiM9UffjDiDi+dZW3RkTMjoj/jIi1EbEmIj5YLbfPhhARXRFxT0T8oOqvq6rlcyLi7qq/bqq+XEP1ZZmbqv66OyK6W1l/q0RER0Ssioh/rebtr92IiPURcV9ErI6InmqZf5PDiIgDI2JZRPy4+rfsdfZXc7VVyIoXhgh6MzAPOC9qQ/8IlgBnDlp2GXBbZs4FbqvmodZ/c6vXJcDfjVKNY0kf8KeZeTRwIvD+6nfJPhvaVuANmXkcsAA4MyJOpDYE17VVfz1NbYguqBuqC7i2ateOPgisrZu3v0b2PzJzQd2jB/ybHN6ngX/LzFcBx1H7XbO/mikz2+YFvA64tW7+cuDyVtc1Vl5AN3B/3fwDwMuq6ZcBD1TTfw+cN1S7dn0B/0xtfE/7bOS+2g/4PrWRI54EOqvlO/8+qX2b+XXVdGfVLlpd+yj30yxq/5F7A/Cv1B7ubH/tvs/WA4cMWubf5NB9dQDw88G/J/ZXc19tdSaLoYcIau0wP2Pbb2TmowDV+0ur5fZjnerSzKuBu7HPhlVd+lpN7bH7/wH8DHgmMwfGL6rvk12G6gIGhupqJ58CPgIMDCY6E/trJAn8e0SsjNpIIuDf5HCOADYA/7e6JP2FiJiO/dVU7RayGhrmRyOyHysR8RLgFuBPMnN34/K0fZ9l5o7MXEDtDM0i4OihmlXvbd1fEfFW4InMXFm/eIim9teuTs7M46ld2np/RPzObtq2e591AscDf5eZrwae44VLg0Np9/7aK+0Wshoa5kc7PR4RLwOo3gcG/rMfgYiYTC1gfSUz/7FabJ+NIDOfAb5N7V62A6M2FBfs2ic7+yt2HaqrXZwMnBUR64EbqV0y/BT2125l5iPV+xPAP1EL8/5NDq0X6M3Mu6v5ZdRCl/3VRO0WshoZIkgvqB8u6UJq9x0NLL+g+rbJicCmgdPL7SIigtpIB2sz8//UrbLPhhARh0bEgdX0NOCN1G6y/U9qQ3HBi/trqKG62kJmXp6ZszKzm9q/U7dn5vnYX8OKiOkRsf/ANHAGcD/+TQ4pMx8DHoqIV1aLTqc2Oov91UytvilstF/AW4CfULsf5GOtrmesvICvAo8C26n9H8vF1O7puA34afV+cNU2qH1L82fAfcDCVtffgv46hdqp8h8Cq6vXW+yzYftrPrCq6q/7gSuq5UdQG890HfA1YGq1vKuaX1etP6LVn6GFfXca8K/214j9dATwg+q1ZuDfd/8md9tnC4Ce6u/y68BB9ldzXz7xXZIkqYB2u1woSZI0KgxZkiRJBRiyJEmSCjBkSZIkFWDIkiRJKsCQJUmSVIAhS1JREfHfe9D2ooi4rmQ9oy0i/ioi1kTE2oj4TPUgW0ltwJAlqajMPKnVNbRKRJxEbYic+cBvA68BTm1pUZJGjSFLUlERsbl6f1lE3BERqyPi/oh4fbX8vRHxk4j4L2qBZHf7OjwibouIH1bvr6iW/1ZEfC8i7o2IqweOOcw+TouI/4qIm6vj/mVEnB8R90TEfRHxWyMca0lELK7b37DHojYqQBcwBZgKTAYeb6DbJE0AhixJo+X3gVszcwFwHLC6GoD2Kmrh6k3AvBH2cR3w5cycD3wF+Ey1/NPApzPzNTQ2aO1xwAeBY4H3AEdl5iLgC8AHRjhWwzLzu9TGG3y0et2amWv3dD+SxidDlqTRci/w3oi4Ejg2M58FXgt8OzM3ZOY24KYR9vE64B+q6aXUxpAcWP61avofBm80VC2Z+WhmbqU2Ftu/V8vvA7pHOFbDIuJI4GhgFnAY8IaI+J093Y+k8cmQJWlUZOYdwO8ADwNLI+KCgVX7stu93G5r3XR/3Xw/0DnCsfqo/u2sbmKfspvjnAN8LzM3Z+Zm4JvAiXtZs6RxxpAlaVRExOHAE5n5eeCLwPHA3cBpETEzIiYD7xhhN/8NnFtNnw/cWU1/D/i9avrcwRvtpeGOtR44oZo+m9p9VsP5JXBqRHRWn+9UwMuFUpsY7v/YJKnZTgM+HBHbgc3ABZn5aHX58LvU7ln6PtCxm338MfCliPgwsAF4b7X8T4D/FxF/CnwD2NSEeoc71ueBf46Ie4DbgOd2s49lwBuoXYZM4N8y81+aUJukcSAy9+VMvSS1XkTsB/w6MzMizgXOy8yzW12XpPbmmSxJE8EJwHXVPVLPAP+zxfVIkmeyJI09EfExXnx/1tcy85o92Mex1L4VWG9rZr52X+tr5bEkjR+GLEmSpAL8dqEkSVIBhixJkqQCDFmSJEkFGLIkSZIKMGRJkiQV8P8Bn08q+3vFHC0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting isd_og_mou_8 predictor for churn and not churn customers\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "sns.distplot(data_churn['isd_og_mou_8'],label='churn',hist=False)\n",
    "sns.distplot(data_non_churn['isd_og_mou_8'],label='not churn',hist=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the ISD outgoing minutes of usage for the month of August for churn customers is densed approximately to zero. On the onther hand for the non churn customers it is little more than the churn customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting monthly_3g_8 predictor for churn and not churn customers\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "sns.distplot(data_churn['monthly_3g_8'],label='churn',hist=False)\n",
    "sns.distplot(data_non_churn['monthly_3g_8'],label='not churn',hist=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of mothly 3g data for August for the churn customers are very much populated aroud 1, whereas of non churn customers it spreaded accross various numbers.\n",
    "\n",
    "Similarly we can plot each variables, which have higher coefficients, churn distribution."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
